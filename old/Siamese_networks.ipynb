{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PuxL0-qUFBm5cew0WnhybFpbrXys_OHi",
      "authorship_tag": "ABX9TyNvhcxmP8i7qYLwS6Auyi9k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pianonyy/UPLIFT_modeling/blob/master/Siamese_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsvphRCT4Xr_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.utils.extmath import stable_cumsum\n",
        "from sklearn.utils.validation import check_consistent_length\n",
        "from sklearn.metrics import auc"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2SJ-abn1cFt"
      },
      "source": [
        "\n",
        "\n",
        "def qini_curve(y_true, uplift, treatment): #think about names uplift score?\n",
        "\n",
        "    y_true, uplift, treatment = np.array(y_true), np.array(uplift), np.array(treatment)\n",
        "\n",
        "    desc_score_indices = np.argsort(uplift, kind=\"mergesort\")[::-1]\n",
        "\n",
        "    y_true = y_true[desc_score_indices]\n",
        "    treatment = treatment[desc_score_indices]\n",
        "    uplift = uplift[desc_score_indices]\n",
        "\n",
        "    y_true_ctrl, y_true_trmnt = y_true.copy(), y_true.copy()\n",
        "\n",
        "    y_true_ctrl[treatment == 1] = 0\n",
        "    y_true_trmnt[treatment == 0] = 0\n",
        "\n",
        "    distinct_value_indices = np.where(np.diff(uplift))[0]\n",
        "    threshold_indices = np.r_[distinct_value_indices, uplift.size - 1]\n",
        "\n",
        "    #print(threshold_indices.size)\n",
        "\n",
        "    num_trmnt = stable_cumsum(treatment)[threshold_indices]\n",
        "    y_trmnt = stable_cumsum(y_true_trmnt)[threshold_indices]\n",
        "\n",
        "    num_all = threshold_indices + 1\n",
        "\n",
        "    num_ctrl = num_all - num_trmnt\n",
        "    y_ctrl = stable_cumsum(y_true_ctrl)[threshold_indices]\n",
        "\n",
        "    curve_values = y_trmnt - y_ctrl * np.divide(num_trmnt, num_ctrl, out=np.zeros_like(num_trmnt), where=num_ctrl != 0)\n",
        "    if num_all.size == 0 or curve_values[0] != 0 or num_all[0] != 0:\n",
        "       \n",
        "        num_all = np.r_[0, num_all]\n",
        "        curve_values = np.r_[0, curve_values]\n",
        "\n",
        "    return num_all, curve_values\n",
        "\n",
        "def perfect_qini_curve(y_true, treatment):\n",
        "  \n",
        "    check_consistent_length(y_true, treatment)\n",
        "    n_samples = len(y_true)\n",
        "\n",
        "    y_true, treatment = np.array(y_true), np.array(treatment)\n",
        "\n",
        "    \n",
        "    \n",
        "    x_perfect, y_perfect = qini_curve(\n",
        "            y_true, y_true * treatment - y_true * (1 - treatment), treatment\n",
        "    )\n",
        "    \n",
        "\n",
        "    return x_perfect, y_perfect\n",
        "\n",
        "def qini_auc_score(y_true, uplift, treatment, negative_effect=True):\n",
        "   \n",
        "    check_consistent_length(y_true, uplift, treatment)\n",
        "\n",
        "    y_true, uplift, treatment = np.array(y_true), np.array(uplift), np.array(treatment)\n",
        "\n",
        "    treatment_count = np.count_nonzero(treatment == 1)\n",
        "\n",
        "\n",
        "    x_model, y_model = qini_curve(y_true, uplift, treatment)\n",
        "    x_perfect, y_perfect = perfect_qini_curve(y_true, treatment)\n",
        "    x_baseline, y_baseline = np.array([0, x_perfect[-1]]), np.array([0, y_perfect[-1]])\n",
        "    \n",
        "    # print(np.size(treatment))\n",
        "    #x_baseline, y_baseline = np.array([np.arange(0, np.size(treatment))]), np.array([0, y_perfect[-1]])\n",
        "    \n",
        "\n",
        "    auc_score_baseline = auc(x_baseline, y_baseline)\n",
        "    auc_score_perfect = auc(x_perfect, y_perfect) - auc_score_baseline\n",
        "    auc_score_model = auc(x_model, y_model) - auc_score_baseline\n",
        "\n",
        "    return auc_score_model\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQSBY7CdGF-U"
      },
      "source": [
        "import logging\n",
        "from os.path import join as pjoin\n",
        "from typing import Tuple\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "N_PURCHASES_ROWS = None\n",
        "DATA_PATH = '/content/drive/MyDrive/' \n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def load_clients() -> pd.DataFrame:\n",
        "    return pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'clients.csv'),\n",
        "        parse_dates=['first_issue_date', 'first_redeem_date'],\n",
        "    )\n",
        "\n",
        "\n",
        "def prepare_clients() -> Tuple[pd.DataFrame, LabelEncoder]:\n",
        "    logger.info('Preparing clients...')\n",
        "    clients = load_clients()\n",
        "    client_encoder = LabelEncoder()\n",
        "    clients['client_id'] = client_encoder.fit_transform(clients['client_id'])\n",
        "    logger.info('Clients are ready')\n",
        "    return clients, client_encoder\n",
        "\n",
        "\n",
        "def load_products() -> pd.DataFrame:\n",
        "    return pd.read_csv(pjoin(DATA_PATH, 'products.csv'))\n",
        "\n",
        "\n",
        "def prepare_products() -> Tuple[pd.DataFrame, LabelEncoder]:\n",
        "    logger.info('Preparing products...')\n",
        "    products = load_products()\n",
        "    product_encoder = LabelEncoder()\n",
        "    products['product_id'] = product_encoder. \\\n",
        "        fit_transform(products['product_id'])\n",
        "\n",
        "    products.fillna(-1, inplace=True)\n",
        "\n",
        "    for col in [\n",
        "        'level_1', 'level_2', 'level_3', 'level_4',\n",
        "        'segment_id', 'brand_id', 'vendor_id',\n",
        "    ]:\n",
        "        products[col] = LabelEncoder().fit_transform(products[col].astype(str))\n",
        "    logger.info('Products are ready')\n",
        "    return products, product_encoder\n",
        "\n",
        "\n",
        "def load_purchases() -> pd.DataFrame:\n",
        "    logger.info('Loading purchases...')\n",
        "    purchases = pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'purchases.csv'),\n",
        "        nrows=N_PURCHASES_ROWS,\n",
        "    )\n",
        "    logger.info('Purchases are loaded')\n",
        "    return purchases\n",
        "\n",
        "\n",
        "def prepare_purchases(\n",
        "        client_encoder: LabelEncoder,\n",
        "        product_encoder: LabelEncoder,\n",
        ") -> pd.DataFrame:\n",
        "    logger.info('Preparing purchases...')\n",
        "    purchases = load_purchases()\n",
        "\n",
        "    logger.info('Handling n/a values...')\n",
        "    purchases.dropna(\n",
        "        subset=['client_id', 'product_id'],\n",
        "        how='any',\n",
        "        inplace=True,\n",
        "    )\n",
        "    purchases.fillna(-1, inplace=True)\n",
        "\n",
        "    logger.info('Label encoding...')\n",
        "    purchases['client_id'] = client_encoder.transform(purchases['client_id'])\n",
        "    purchases['product_id'] = product_encoder.transform(purchases['product_id'])\n",
        "    for col in ['transaction_id', 'store_id']:\n",
        "        purchases[col] = LabelEncoder(). \\\n",
        "            fit_transform(purchases[col].astype(str))\n",
        "\n",
        "    logger.info('Date and time conversion...')\n",
        "    purchases['datetime'] = pd.to_datetime(\n",
        "        purchases['transaction_datetime'],\n",
        "        format='%Y-%m-%d %H:%M:%S',\n",
        "    )\n",
        "    purchases.drop(columns=['transaction_datetime'], inplace=True)\n",
        "\n",
        "    logger.info('Purchases are ready')\n",
        "    return purchases\n",
        "\n",
        "\n",
        "def load_train() -> pd.DataFrame:\n",
        "    return pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'uplift_train.csv'),\n",
        "        index_col='client_id',\n",
        "    )\n",
        "\n",
        "\n",
        "def load_test() -> pd.DataFrame:\n",
        "    return pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'uplift_test.csv'),\n",
        "        index_col='client_id',\n",
        "    )\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8JO4biyK97B",
        "outputId": "bf2e4429-0e70-430e-8666-d948c032efd2"
      },
      "source": [
        "!unzip /content/drive/MyDrive/features.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/features.zip\n",
            "  inflating: features.pkl            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et_g8OCuS1Fi",
        "outputId": "7f67802c-d6dd-4ad0-8ad0-9f349a3f99c6"
      },
      "source": [
        "!pip install pickle5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 26.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 92kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 102kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 112kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 122kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 7.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp36-cp36m-linux_x86_64.whl size=218626 sha256=0f54652b5f4a700388e7df5cc4b0f98528425ced351a00c955da195779025332\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV94X1S55omZ",
        "outputId": "ade51bbe-27aa-4cad-8f31-aa5c44487f85"
      },
      "source": [
        "import pickle5\n",
        "RANDOM_STATE = 12\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = load_train()\n",
        "indices_train = train.index\n",
        "with open('features.pkl', 'rb') as f:\n",
        "        features: pd.DataFrame = pickle5.load(f)\n",
        "\n",
        "features.set_index('client_id', inplace=True)\n",
        "X_train = features.loc[indices_train, :]\n",
        "\n",
        "\n",
        "\n",
        "treatment_train = train.loc[indices_train, 'treatment_flg'].values\n",
        "y_train = train.loc[indices_train, 'target'].values\n",
        "\n",
        "X_train['treatment'] = treatment_train\n",
        "X_train['target'] = y_train\n",
        "\n",
        "X_train.loc[(X_train['target'] == 1) & (X_train['treatment'] == 1),'Z_trans'] = 2 \n",
        "X_train.loc[(X_train['target'] == 0) & (X_train['treatment'] == 0),'Z_trans'] = -2\n",
        "X_train.loc[X_train['Z_trans'].isnull(), 'Z_trans'] = 0\n",
        "\n",
        "# Z_trans = X_train['Z_trans']\n",
        "\n",
        "\n",
        "indices_learn, indices_valid = train_test_split(\n",
        "        X_train.index,\n",
        "        test_size=0.3,\n",
        "        random_state = RANDOM_STATE,\n",
        ")\n",
        "\n",
        "all = X_train.copy()\n",
        "X_train =all.loc[indices_learn,]\n",
        "X_test = all.loc[indices_valid,]\n",
        "\n",
        "\n",
        "treatment_train = X_train['treatment']\n",
        "y_train = X_train['target']\n",
        "Z_trans_train = X_train['Z_trans']\n",
        "\n",
        "treatment_test = X_test['treatment']\n",
        "y_test = X_test['target']\n",
        "Z_trans_test = X_test['Z_trans']\n",
        "\n",
        "\n",
        "X_train=X_train.drop('Z_trans',axis = 1)\n",
        "X_train=X_train.drop('target',axis = 1)\n",
        "X_train=X_train.drop('treatment',axis = 1)\n",
        "\n",
        "X_test=X_test.drop('Z_trans',axis = 1)\n",
        "X_test=X_test.drop('target',axis = 1)\n",
        "X_test=X_test.drop('treatment',axis = 1)\n",
        "\n",
        "print(treatment_train)\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "client_id\n",
            "5803624422    1\n",
            "20b7b05f7d    0\n",
            "0c10e0113f    1\n",
            "1761677f2d    1\n",
            "aa188a0008    0\n",
            "             ..\n",
            "4ef8dd16ad    1\n",
            "a54f58238b    1\n",
            "2e7eeaca71    1\n",
            "332b911361    1\n",
            "c13eba9d88    1\n",
            "Name: treatment, Length: 140024, dtype: int64\n",
            "            gender_M  gender_F  ...  brand_id_nunique  vendor_id_nunique\n",
            "client_id                       ...                                     \n",
            "5803624422         0         0  ...                26                 20\n",
            "20b7b05f7d         1         0  ...                54                 42\n",
            "0c10e0113f         0         0  ...                41                 31\n",
            "1761677f2d         0         0  ...                51                 47\n",
            "aa188a0008         1         0  ...                24                 20\n",
            "...              ...       ...  ...               ...                ...\n",
            "4ef8dd16ad         0         1  ...               105                 86\n",
            "a54f58238b         0         0  ...                33                 29\n",
            "2e7eeaca71         0         0  ...                60                 54\n",
            "332b911361         0         1  ...                24                 22\n",
            "c13eba9d88         0         0  ...                62                 61\n",
            "\n",
            "[140024 rows x 333 columns]\n",
            "            gender_M  gender_F  ...  brand_id_nunique  vendor_id_nunique\n",
            "client_id                       ...                                     \n",
            "353f2648f3         0         0  ...                11                  9\n",
            "f0d6002166         0         1  ...                22                 19\n",
            "af4f3039fe         0         0  ...                 7                  8\n",
            "34b4ce6c2a         0         1  ...                23                 22\n",
            "7046ea76d3         0         1  ...                22                 18\n",
            "...              ...       ...  ...               ...                ...\n",
            "d5c9592f5f         0         0  ...                67                 51\n",
            "555d2436d3         0         0  ...                29                 25\n",
            "bc21e85e6e         0         1  ...                51                 43\n",
            "aa4d24e82f         0         0  ...                47                 39\n",
            "ad18c83a2e         0         0  ...                36                 29\n",
            "\n",
            "[60011 rows x 333 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEkkrFERTR6O",
        "outputId": "4b5adc71-9a86-4838-e31f-67e8bece3ccc"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "import numpy as np\n",
        "\n",
        "\n",
        "scaler = StandardScaler(with_std = False, with_mean = False)\n",
        "\n",
        "X_train_0 = X_train.copy()\n",
        "X_train_0['treatment'] = 0\n",
        "\n",
        "X_train_1 = X_train.copy()\n",
        "X_train_1['treatment'] = 1\n",
        "# print(X_train_1)\n",
        "# print(X_train_0)\n",
        "X_train_1 = X_train_1.astype('float32')\n",
        "X_train_1 = X_train_1.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_train_1 = scaler.fit_transform(X_train_1)\n",
        "\n",
        "\n",
        "print(X_train_1)\n",
        "X_train_0 = X_train_0.astype('float32')\n",
        "X_train_0 = X_train_0.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_train_0 = scaler.fit_transform(X_train_0)\n",
        "\n",
        "print(X_train_0)\n",
        "X_test_0 = X_test.copy()\n",
        "X_test_0['treatment'] = 0\n",
        "\n",
        "X_test_1 = X_test.copy()\n",
        "X_test_1['treatment'] = 1\n",
        "\n",
        "X_test_1 = X_test_1.astype('float32')\n",
        "X_test_1 = X_test_1.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_test_1 = scaler.fit_transform(X_test_1)\n",
        "\n",
        "X_test_0 = X_test_0.astype('float32')\n",
        "X_test_0 = X_test_0.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_test_0 = scaler.fit_transform(X_test_0)\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.  0.  1. ... 26. 20.  1.]\n",
            " [ 1.  0.  0. ... 54. 42.  1.]\n",
            " [ 0.  0.  1. ... 41. 31.  1.]\n",
            " ...\n",
            " [ 0.  0.  1. ... 60. 54.  1.]\n",
            " [ 0.  1.  0. ... 24. 22.  1.]\n",
            " [ 0.  0.  1. ... 62. 61.  1.]]\n",
            "[[ 0.  0.  1. ... 26. 20.  0.]\n",
            " [ 1.  0.  0. ... 54. 42.  0.]\n",
            " [ 0.  0.  1. ... 41. 31.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ... 60. 54.  0.]\n",
            " [ 0.  1.  0. ... 24. 22.  0.]\n",
            " [ 0.  0.  1. ... 62. 61.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFLXT97dapoc"
      },
      "source": [
        "example of siamese network!!!!\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "qzEBJvdtZdi-",
        "outputId": "26fd015f-8656-4515-c7f2-435ae7e1f689"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 55   # Number of samples in each batch\n",
        "epoch_num = 12      # Number of epochs to train the network\n",
        "lr = 0.001        # Learning rate\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 100)\n",
        "        self.fc3 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return torch.exp(F.log_softmax(x,dim=1))    # F.log_softmax = log( exp(x_i) / exp(x).sum() )\n",
        "        #return x\n",
        "\n",
        "\n",
        "\n",
        "model = Model()\n",
        "alpha = 0.9\n",
        "\n",
        "\n",
        "# calculate the number of batches per epoch\n",
        "batch_per_ep = X_train.shape[0] // batch_size\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# X_test_1_tensor = torch.FloatTensor(X_test_1)\n",
        "# X_test_0_tensor = torch.FloatTensor(X_test_0)\n",
        "\n",
        "# treatment_test = treatment_test.to_numpy()\n",
        "# treatment_test = torch.from_numpy(treatment_test).int()\n",
        "# treatment_test = Variable(treatment_test)\n",
        "\n",
        "# y_test = y_test.to_numpy()\n",
        "# y_test = torch.from_numpy(y_test ).float()\n",
        "# y_test  = Variable(y_test )\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# Z_trans_test = Z_trans_test.to_numpy()\n",
        "# Z_trans_test = torch.from_numpy(Z_trans_test).float()\n",
        "# Z_trans_test = Variable(Z_trans_test)\n",
        "\n",
        "# Z_trans_test = torch.reshape(Z_trans_test, (X_test_1.shape[0],1))\n",
        "\n",
        "all_losses  = []\n",
        "test_losses = []\n",
        "min_losses = []\n",
        "\n",
        "for ep in range(epoch_num):  # epochs loop\n",
        "    print(\"..........................epoch =\",ep,\"..........................\")\n",
        "    i = 0\n",
        "    for batch_n in range(batch_per_ep):  # batches loop\n",
        "        batch_loss = []\n",
        "       \n",
        "        \n",
        "        batch_1_feat = torch.FloatTensor(X_train_1[i:i+batch_size])\n",
        "        batch_0_feat = torch.FloatTensor(X_train_0[i:i+batch_size])\n",
        "        \n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        batch_Z_trans = Z_trans_train[i:i+batch_size]\n",
        "\n",
        "        # Reset gradients\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        mu_1 = model(batch_1_feat)\n",
        "        mu_0 = model(batch_0_feat)\n",
        "\n",
        "        mu_1_target_class = mu_1[:,1]\n",
        "        mu_0_target_class = mu_0[:,1]\n",
        "\n",
        "        treatment_batch = treatment_train[i:i+batch_size]\n",
        "        treatment_batch = treatment_batch.to_numpy()\n",
        "        treatment_batch = torch.from_numpy(treatment_batch).int()\n",
        "        treatment_batch = Variable(treatment_batch)\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, (batch_size,1))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, (batch_size,1))\n",
        "        #convert to torch structure\n",
        "        batch_label = batch_label.to_numpy()\n",
        "        batch_label = torch.from_numpy(batch_label).float()\n",
        "        batch_label = Variable(batch_label)\n",
        "\n",
        "       \n",
        "        #convert to torch structure\n",
        "        batch_Z_trans = batch_Z_trans.to_numpy()\n",
        "        batch_Z_trans = torch.from_numpy(batch_Z_trans).float()\n",
        "        batch_Z_trans = Variable(batch_Z_trans)\n",
        "\n",
        "        batch_Z_trans = torch.reshape(batch_Z_trans, (batch_size,1))\n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "        \n",
        "\n",
        "        \n",
        "        loss_contrastive = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "        \n",
        "        batch_loss.append(loss_contrastive)\n",
        "        \n",
        "\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Backward pass and updates\n",
        "        loss_contrastive.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        i += batch_size\n",
        "        #end for!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss)) \n",
        "    #work with test dataset\n",
        "\n",
        "    # mu_1 = model(X_test_1_tensor)\n",
        "    # mu_0 = model(X_test_0_tensor)\n",
        "\n",
        "    # mu_1_target_class = mu_1[:,1]\n",
        "    # mu_0_target_class = mu_0[:,1]\n",
        "\n",
        "    # ones = np.ones(shape = X_test_1.shape[0])\n",
        "    # ones = torch.from_numpy(ones).float()\n",
        "\n",
        "    # #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "    # uplift_pred_Y = treatment_test * mu_1_target_class + (ones - treatment_test) * mu_0_target_class \n",
        "\n",
        "    # mu_0_target_class = torch.reshape(mu_0_target_class, (X_test_1.shape[0],1))\n",
        "    # mu_1_target_class = torch.reshape(mu_1_target_class, (X_test_1.shape[0],1))\n",
        "    \n",
        "\n",
        "    \n",
        "   \n",
        "    \n",
        "    # #declare losses\n",
        "    # loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "    # loss_MSE = nn.MSELoss()\n",
        "\n",
        "    # #implements uplift_predicted = mu_1 - mu_0\n",
        "    # uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "\n",
        "    # loss_contrastive =torch.mean(  (1-alpha) * loss_MSE(Z_trans_test, uplift_pred) + alpha * loss_cross( uplift_pred_Y, y_test))\n",
        "    # test_losses.append(loss_contrastive)\n",
        "    \n",
        "    # print(qini_auc_score(y_test.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_test.cpu().detach().numpy() ))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_losses,color='blue')\n",
        "# plt.plot(test_losses, color='green')\n",
        "plt.title('Contrastive Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(all_losses,color='blue')\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..........................epoch = 0 ..........................\n",
            "..........................epoch = 1 ..........................\n",
            "..........................epoch = 2 ..........................\n",
            "..........................epoch = 3 ..........................\n",
            "..........................epoch = 4 ..........................\n",
            "..........................epoch = 5 ..........................\n",
            "..........................epoch = 6 ..........................\n",
            "..........................epoch = 7 ..........................\n",
            "..........................epoch = 8 ..........................\n",
            "..........................epoch = 9 ..........................\n",
            "..........................epoch = 10 ..........................\n",
            "..........................epoch = 11 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "yOQ_S5FGayLT",
        "outputId": "3c9c410c-9530-4e47-c7a2-91aacf4dc3df"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 55   # Number of samples in each batch\n",
        "epoch_num = 20      # Number of epochs to train the network\n",
        "lr = 0.001        # Learning rate\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3 = nn.Linear(200, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return torch.exp(F.log_softmax(x,dim=1))\n",
        "        #return x\n",
        "\n",
        "\n",
        "\n",
        "model = Model()\n",
        "alpha = 0.8\n",
        "\n",
        "\n",
        "# calculate the number of batches per epoch\n",
        "batch_per_ep = X_train.shape[0] // batch_size\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "all_losses  = []\n",
        "min_losses =[]\n",
        "for ep in range(epoch_num):  # epochs loop\n",
        "    print(\"..........................epoch =\",ep,\"..........................\")\n",
        "    i = 0\n",
        "    for batch_n in range(batch_per_ep):  # batches loop\n",
        "        batch_loss = []\n",
        "       \n",
        "        \n",
        "        batch_1_feat = torch.FloatTensor(X_train_1[i:i+batch_size])\n",
        "        batch_0_feat = torch.FloatTensor(X_train_0[i:i+batch_size])\n",
        "        \n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        batch_Z_trans = Z_trans[i:i+batch_size]\n",
        "\n",
        "        # Reset gradients\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        mu_1 = model(batch_1_feat)\n",
        "        mu_0 = model(batch_0_feat)\n",
        "\n",
        "        mu_1_target_class = mu_1[:,1]\n",
        "        mu_0_target_class = mu_0[:,1]\n",
        "\n",
        "        treatment_batch = treatment_train[i:i+batch_size]\n",
        "        treatment_batch = torch.from_numpy(treatment_batch).int()\n",
        "        treatment_batch = Variable(treatment_batch)\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, (batch_size,1))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, (batch_size,1))\n",
        "        #convert to torch structure\n",
        "        batch_label = torch.from_numpy(batch_label).float()\n",
        "        batch_label = Variable(batch_label)\n",
        "\n",
        "       \n",
        "        #convert to torch structure\n",
        "        batch_Z_trans = batch_Z_trans.to_numpy()\n",
        "        batch_Z_trans = torch.from_numpy(batch_Z_trans).float()\n",
        "        batch_Z_trans = Variable(batch_Z_trans)\n",
        "\n",
        "        batch_Z_trans = torch.reshape(batch_Z_trans, (batch_size,1))\n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "\n",
        "        loss_contrastive =torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "\n",
        "        batch_loss.append(loss_contrastive)\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Backward pass and updates\n",
        "        loss_contrastive.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        i += batch_size\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss)) \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_losses)\n",
        "plt.title('Contrastive Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..........................epoch = 0 ..........................\n",
            "..........................epoch = 1 ..........................\n",
            "..........................epoch = 2 ..........................\n",
            "..........................epoch = 3 ..........................\n",
            "..........................epoch = 4 ..........................\n",
            "..........................epoch = 5 ..........................\n",
            "..........................epoch = 6 ..........................\n",
            "..........................epoch = 7 ..........................\n",
            "..........................epoch = 8 ..........................\n",
            "..........................epoch = 9 ..........................\n",
            "..........................epoch = 10 ..........................\n",
            "..........................epoch = 11 ..........................\n",
            "..........................epoch = 12 ..........................\n",
            "..........................epoch = 13 ..........................\n",
            "..........................epoch = 14 ..........................\n",
            "..........................epoch = 15 ..........................\n",
            "..........................epoch = 16 ..........................\n",
            "..........................epoch = 17 ..........................\n",
            "..........................epoch = 18 ..........................\n",
            "..........................epoch = 19 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "vCOiW7WcMNUc",
        "outputId": "c82775ca-ea46-4934-cc0f-60f8ccaa660d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_losses[:210000])\n",
        "plt.title('Contrastive Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz4cLfVvZHIL"
      },
      "source": [
        "another network with sigmoid \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i3IxOEpZZEXc",
        "outputId": "7af45321-c661-4012-b301-4c3b1891d0f3"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 1522   # Number of samples in each batch\n",
        "epoch_num = 19      # Number of epochs to train the network\n",
        "lr = 0.001        # Learning rate\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 100)\n",
        "        self.fc3 = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        m = nn.Sigmoid()\n",
        "        return m(x)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "model = Model()\n",
        "alpha = 0.3\n",
        "\n",
        "\n",
        "# calculate the number of batches per epoch\n",
        "batch_per_ep = X_train.shape[0] // batch_size\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# X_test_1_tensor = torch.FloatTensor(X_test_1)\n",
        "# X_test_0_tensor = torch.FloatTensor(X_test_0)\n",
        "\n",
        "# treatment_test = treatment_test.to_numpy()\n",
        "# treatment_test = torch.from_numpy(treatment_test).int()\n",
        "# treatment_test = Variable(treatment_test)\n",
        "\n",
        "# y_test = y_test.to_numpy()\n",
        "# y_test = torch.from_numpy(y_test ).float()\n",
        "# y_test  = Variable(y_test )\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# Z_trans_test = Z_trans_test.to_numpy()\n",
        "# Z_trans_test = torch.from_numpy(Z_trans_test).float()\n",
        "# Z_trans_test = Variable(Z_trans_test)\n",
        "\n",
        "# Z_trans_test = torch.reshape(Z_trans_test, (X_test_1.shape[0],1))\n",
        "\n",
        "all_losses  = []\n",
        "test_losses = []\n",
        "min_losses = []\n",
        "for ep in range(epoch_num):  # epochs loop\n",
        "    print(\"..........................epoch =\",ep,\"..........................\")\n",
        "    i = 0\n",
        "    for batch_n in range(batch_per_ep):  # batches loop\n",
        "        batch_loss = []\n",
        "       \n",
        "        \n",
        "        batch_1_feat = torch.FloatTensor(X_train_1[i:i+batch_size])\n",
        "        batch_0_feat = torch.FloatTensor(X_train_0[i:i+batch_size])\n",
        "        \n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        batch_Z_trans = Z_trans_train[i:i+batch_size]\n",
        "\n",
        "        \n",
        "        # Forward pass\n",
        "        mu_1 = model(batch_1_feat)\n",
        "        mu_0 = model(batch_0_feat)\n",
        "\n",
        "        print(mu_1)\n",
        "        print(mu_0)\n",
        "        mu_1_target_class = mu_1   \n",
        "        mu_0_target_class = mu_0   \n",
        "\n",
        "        treatment_batch = treatment_train[i:i+batch_size]\n",
        "        treatment_batch = treatment_batch.to_numpy()\n",
        "        treatment_batch = torch.from_numpy(treatment_batch).int()\n",
        "        treatment_batch = Variable(treatment_batch)\n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\n",
        "        \n",
        "        \n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "        \n",
        "\n",
        "        # mu_0_target_class = torch.reshape(mu_0_target_class, (batch_size,1))\n",
        "        # mu_1_target_class = torch.reshape(mu_1_target_class, (batch_size,1))\n",
        "        #convert to torch structure\n",
        "        batch_label = batch_label.to_numpy()\n",
        "        batch_label = torch.from_numpy(batch_label).float()\n",
        "        batch_label = Variable(batch_label)\n",
        "\n",
        "       \n",
        "        #convert to torch structure\n",
        "        batch_Z_trans = batch_Z_trans.to_numpy()\n",
        "        batch_Z_trans = torch.from_numpy(batch_Z_trans).float()\n",
        "        batch_Z_trans = Variable(batch_Z_trans)\n",
        "\n",
        "        batch_Z_trans = torch.reshape(batch_Z_trans, shape = (-1,))\n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "        \n",
        "        # print(\"train uplift: \", uplift_pred)\n",
        "        print(uplift_pred_Y)\n",
        "        loss_contrastive = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "        # print(loss_contrastive)\n",
        "        batch_loss.append(loss_contrastive)\n",
        "        # print(\"train AUQC:\", qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Backward pass and updates\n",
        "        loss_contrastive.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        i += batch_size\n",
        "        #end for!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss)) \n",
        "    #work with test dataset\n",
        "\n",
        "    # mu_1 = model(X_test_1_tensor)\n",
        "    # mu_0 = model(X_test_0_tensor)\n",
        "\n",
        "    # mu_1_target_class = mu_1\n",
        "    # mu_0_target_class = mu_0\n",
        "\n",
        "    # ones = np.ones(shape = X_test_1.shape[0])\n",
        "    # ones = torch.from_numpy(ones).float()\n",
        "\n",
        "    # #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "    # uplift_pred_Y = treatment_test * mu_1_target_class + (ones - treatment_test) * mu_0_target_class \n",
        "\n",
        "    # mu_0_target_class = torch.reshape(mu_0_target_class, (X_test_1.shape[0],1))\n",
        "    # mu_1_target_class = torch.reshape(mu_1_target_class, (X_test_1.shape[0],1))\n",
        "    \n",
        "\n",
        "    \n",
        "   \n",
        "    \n",
        "    # #declare losses\n",
        "    # loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "    # loss_MSE = nn.MSELoss()\n",
        "\n",
        "    # #implements uplift_predicted = mu_1 - mu_0\n",
        "    # uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "\n",
        "    # loss_contrastive =torch.mean(  (1-alpha) * loss_MSE(Z_trans_test, uplift_pred) + alpha * loss_cross( uplift_pred_Y, y_test))\n",
        "    # test_losses.append(loss_contrastive)\n",
        "    \n",
        "    # print(\"test uplift:\", uplift_pred)\n",
        "\n",
        "    # print(\"test AUQC:\", qini_auc_score(y_test.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_test.cpu().detach().numpy() ))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_losses,color='blue')\n",
        "#plt.plot(test_losses, color='green')\n",
        "plt.title('Contrastive Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(all_losses,color='blue')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..........................epoch = 0 ..........................\n",
            "tensor([[1.2582e-08],\n",
            "        [1.2756e-35],\n",
            "        [2.6402e-20],\n",
            "        ...,\n",
            "        [4.9793e-37],\n",
            "        [2.0945e-12],\n",
            "        [1.0996e-37]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.2518e-08],\n",
            "        [1.2669e-35],\n",
            "        [2.6256e-20],\n",
            "        ...,\n",
            "        [4.9660e-37],\n",
            "        [2.0794e-12],\n",
            "        [1.0951e-37]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1.2582e-08, 1.2669e-35, 2.6402e-20,  ..., 4.9660e-37, 2.0945e-12,\n",
            "        1.0996e-37], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "..........................epoch = 1 ..........................\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward>)\n",
            "tensor([1., 1., 1.,  ..., 1., 1., 1.], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-bca12b9bff9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Backward pass and updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mloss_contrastive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m# calculate the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}