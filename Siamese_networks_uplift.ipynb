{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Siamese_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PuxL0-qUFBm5cew0WnhybFpbrXys_OHi",
      "authorship_tag": "ABX9TyN52Y0jEz3xa1ENsGsSQuRd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pianonyy/UPLIFT_modeling/blob/master/Siamese_networks_uplift.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsvphRCT4Xr_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.utils.extmath import stable_cumsum\n",
        "from sklearn.utils.validation import check_consistent_length\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2SJ-abn1cFt"
      },
      "source": [
        "def qini_curve(y_true, uplift, treatment): #think about names uplift score?\n",
        "\n",
        "    y_true, uplift, treatment = np.array(y_true), np.array(uplift), np.array(treatment)\n",
        "\n",
        "    desc_score_indices = np.argsort(uplift, kind=\"mergesort\")[::-1]\n",
        "\n",
        "    y_true = y_true[desc_score_indices]\n",
        "    treatment = treatment[desc_score_indices]\n",
        "    uplift = uplift[desc_score_indices]\n",
        "\n",
        "    y_true_ctrl, y_true_trmnt = y_true.copy(), y_true.copy()\n",
        "\n",
        "    y_true_ctrl[treatment == 1] = 0\n",
        "    y_true_trmnt[treatment == 0] = 0\n",
        "\n",
        "    distinct_value_indices = np.where(np.diff(uplift))[0]\n",
        "    threshold_indices = np.r_[distinct_value_indices, uplift.size - 1]\n",
        "\n",
        "    #print(threshold_indices.size)\n",
        "\n",
        "    num_trmnt = stable_cumsum(treatment)[threshold_indices]\n",
        "    y_trmnt = stable_cumsum(y_true_trmnt)[threshold_indices]\n",
        "\n",
        "    num_all = threshold_indices + 1\n",
        "\n",
        "    num_ctrl = num_all - num_trmnt\n",
        "    y_ctrl = stable_cumsum(y_true_ctrl)[threshold_indices]\n",
        "\n",
        "    curve_values = y_trmnt - y_ctrl * np.divide(num_trmnt, num_ctrl, out=np.zeros_like(num_trmnt), where=num_ctrl != 0)\n",
        "    if num_all.size == 0 or curve_values[0] != 0 or num_all[0] != 0:\n",
        "       \n",
        "        num_all = np.r_[0, num_all]\n",
        "        curve_values = np.r_[0, curve_values]\n",
        "\n",
        "    return num_all, curve_values\n",
        "\n",
        "def perfect_qini_curve(y_true, treatment):\n",
        "  \n",
        "    check_consistent_length(y_true, treatment)\n",
        "    n_samples = len(y_true)\n",
        "\n",
        "    y_true, treatment = np.array(y_true), np.array(treatment)\n",
        "\n",
        "    \n",
        "    \n",
        "    x_perfect, y_perfect = qini_curve(\n",
        "            y_true, y_true * treatment - y_true * (1 - treatment), treatment\n",
        "    )\n",
        "    \n",
        "\n",
        "    return x_perfect, y_perfect\n",
        "\n",
        "def qini_auc_score(y_true, uplift, treatment, negative_effect=True):\n",
        "   \n",
        "    check_consistent_length(y_true, uplift, treatment)\n",
        "\n",
        "    y_true, uplift, treatment = np.array(y_true), np.array(uplift), np.array(treatment)\n",
        "\n",
        "    treatment_count = np.count_nonzero(treatment == 1)\n",
        "\n",
        "\n",
        "    x_model, y_model = qini_curve(y_true, uplift, treatment)\n",
        "    x_perfect, y_perfect = perfect_qini_curve(y_true, treatment)\n",
        "    x_baseline, y_baseline = np.array([0, x_perfect[-1]]), np.array([0, y_perfect[-1]])\n",
        "    \n",
        "    # print(np.size(treatment))\n",
        "    #x_baseline, y_baseline = np.array([np.arange(0, np.size(treatment))]), np.array([0, y_perfect[-1]])\n",
        "    \n",
        "\n",
        "    auc_score_baseline = auc(x_baseline, y_baseline)\n",
        "    auc_score_perfect = auc(x_perfect, y_perfect) - auc_score_baseline\n",
        "    auc_score_model = auc(x_model, y_model) - auc_score_baseline\n",
        "\n",
        "    return auc_score_model\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQSBY7CdGF-U"
      },
      "source": [
        "import logging\n",
        "from os.path import join as pjoin\n",
        "from typing import Tuple\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "N_PURCHASES_ROWS = None\n",
        "DATA_PATH = '/content/drive/MyDrive/' \n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def load_clients() -> pd.DataFrame:\n",
        "    return pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'clients.csv'),\n",
        "        parse_dates=['first_issue_date', 'first_redeem_date'],\n",
        "    )\n",
        "\n",
        "\n",
        "def prepare_clients() -> Tuple[pd.DataFrame, LabelEncoder]:\n",
        "    logger.info('Preparing clients...')\n",
        "    clients = load_clients()\n",
        "    client_encoder = LabelEncoder()\n",
        "    clients['client_id'] = client_encoder.fit_transform(clients['client_id'])\n",
        "    logger.info('Clients are ready')\n",
        "    return clients, client_encoder\n",
        "\n",
        "\n",
        "def load_products() -> pd.DataFrame:\n",
        "    return pd.read_csv(pjoin(DATA_PATH, 'products.csv'))\n",
        "\n",
        "\n",
        "def prepare_products() -> Tuple[pd.DataFrame, LabelEncoder]:\n",
        "    logger.info('Preparing products...')\n",
        "    products = load_products()\n",
        "    product_encoder = LabelEncoder()\n",
        "    products['product_id'] = product_encoder. \\\n",
        "        fit_transform(products['product_id'])\n",
        "\n",
        "    products.fillna(-1, inplace=True)\n",
        "\n",
        "    for col in [\n",
        "        'level_1', 'level_2', 'level_3', 'level_4',\n",
        "        'segment_id', 'brand_id', 'vendor_id',\n",
        "    ]:\n",
        "        products[col] = LabelEncoder().fit_transform(products[col].astype(str))\n",
        "    logger.info('Products are ready')\n",
        "    return products, product_encoder\n",
        "\n",
        "\n",
        "def load_purchases() -> pd.DataFrame:\n",
        "    logger.info('Loading purchases...')\n",
        "    purchases = pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'purchases.csv'),\n",
        "        nrows=N_PURCHASES_ROWS,\n",
        "    )\n",
        "    logger.info('Purchases are loaded')\n",
        "    return purchases\n",
        "\n",
        "\n",
        "def prepare_purchases(\n",
        "        client_encoder: LabelEncoder,\n",
        "        product_encoder: LabelEncoder,\n",
        ") -> pd.DataFrame:\n",
        "    logger.info('Preparing purchases...')\n",
        "    purchases = load_purchases()\n",
        "\n",
        "    logger.info('Handling n/a values...')\n",
        "    purchases.dropna(\n",
        "        subset=['client_id', 'product_id'],\n",
        "        how='any',\n",
        "        inplace=True,\n",
        "    )\n",
        "    purchases.fillna(-1, inplace=True)\n",
        "\n",
        "    logger.info('Label encoding...')\n",
        "    purchases['client_id'] = client_encoder.transform(purchases['client_id'])\n",
        "    purchases['product_id'] = product_encoder.transform(purchases['product_id'])\n",
        "    for col in ['transaction_id', 'store_id']:\n",
        "        purchases[col] = LabelEncoder(). \\\n",
        "            fit_transform(purchases[col].astype(str))\n",
        "\n",
        "    logger.info('Date and time conversion...')\n",
        "    purchases['datetime'] = pd.to_datetime(\n",
        "        purchases['transaction_datetime'],\n",
        "        format='%Y-%m-%d %H:%M:%S',\n",
        "    )\n",
        "    purchases.drop(columns=['transaction_datetime'], inplace=True)\n",
        "\n",
        "    logger.info('Purchases are ready')\n",
        "    return purchases\n",
        "\n",
        "\n",
        "def load_train() -> pd.DataFrame:\n",
        "    return pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'uplift_train.csv'),\n",
        "        index_col='client_id',\n",
        "    )\n",
        "\n",
        "\n",
        "def load_test() -> pd.DataFrame:\n",
        "    return pd.read_csv(\n",
        "        pjoin(DATA_PATH, 'uplift_test.csv'),\n",
        "        index_col='client_id',\n",
        "    )\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8JO4biyK97B",
        "outputId": "0379b128-c0f0-45f4-a6ec-894692918f74"
      },
      "source": [
        "!unzip /content/drive/MyDrive/features.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/features.zip\n",
            "replace features.pkl? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et_g8OCuS1Fi",
        "outputId": "e912e1cd-a6af-4a45-c339-af5e3de5b7cf"
      },
      "source": [
        "!pip install pickle5"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV94X1S55omZ",
        "outputId": "86d3896a-f991-43cb-d5b5-89ef9e7ca990"
      },
      "source": [
        "import pickle5\n",
        "RANDOM_STATE = 12\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = load_train()\n",
        "indices_train = train.index\n",
        "with open('features.pkl', 'rb') as f:\n",
        "        features: pd.DataFrame = pickle5.load(f)\n",
        "\n",
        "features.set_index('client_id', inplace=True)\n",
        "X_train = features.loc[indices_train, :]\n",
        "\n",
        "\n",
        "\n",
        "treatment_train = train.loc[indices_train, 'treatment_flg'].values\n",
        "y_train = train.loc[indices_train, 'target'].values\n",
        "\n",
        "X_train['treatment'] = treatment_train\n",
        "X_train['target'] = y_train\n",
        "\n",
        "X_train.loc[(X_train['target'] == 1) & (X_train['treatment'] == 1),'Z_trans'] = 2 # 2\n",
        "X_train.loc[(X_train['target'] == 1) & (X_train['treatment'] == 0),'Z_trans'] = 1 # 0\n",
        "X_train.loc[X_train['Z_trans'].isnull(), 'Z_trans'] = 0  #-2\n",
        "\n",
        "# Z_trans = X_train['Z_trans']\n",
        "\n",
        "\n",
        "indices_learn, indices_valid = train_test_split(\n",
        "        X_train.index,\n",
        "        test_size=0.3,\n",
        "        random_state = RANDOM_STATE,\n",
        ")\n",
        "\n",
        "all = X_train.copy()\n",
        "X_train =all.loc[indices_learn,]\n",
        "X_test = all.loc[indices_valid,]\n",
        "\n",
        "\n",
        "treatment_train = X_train['treatment']\n",
        "y_train = X_train['target']\n",
        "Z_trans_train = X_train['Z_trans']\n",
        "\n",
        "treatment_test = X_test['treatment']\n",
        "y_test = X_test['target']\n",
        "Z_trans_test = X_test['Z_trans']\n",
        "\n",
        "\n",
        "X_train=X_train.drop('Z_trans',axis = 1)\n",
        "X_train=X_train.drop('target',axis = 1)\n",
        "X_train=X_train.drop('treatment',axis = 1)\n",
        "\n",
        "X_test=X_test.drop('Z_trans',axis = 1)\n",
        "X_test=X_test.drop('target',axis = 1)\n",
        "X_test=X_test.drop('treatment',axis = 1)\n",
        "\n",
        "\n",
        "# print(treatment_test)\n",
        "# print(treatment_train)\n",
        "\n",
        "print(\"propensity score in train:\", treatment_train[treatment_train == 1].shape[0] / treatment_train.shape[0])\n",
        "print(\"propensity score in test:\", treatment_test[treatment_test == 1].shape[0] / treatment_test.shape[0])\n",
        "\n",
        "print(X_train)\n",
        "print(X_test)\n",
        "\n",
        "print(Z_trans_train[Z_trans_train == 0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "propensity score in train: 0.49853596526309774\n",
            "propensity score in test: 0.5027911549549249\n",
            "            gender_M  gender_F  ...  brand_id_nunique  vendor_id_nunique\n",
            "client_id                       ...                                     \n",
            "5803624422         0         0  ...                26                 20\n",
            "20b7b05f7d         1         0  ...                54                 42\n",
            "0c10e0113f         0         0  ...                41                 31\n",
            "1761677f2d         0         0  ...                51                 47\n",
            "aa188a0008         1         0  ...                24                 20\n",
            "...              ...       ...  ...               ...                ...\n",
            "4ef8dd16ad         0         1  ...               105                 86\n",
            "a54f58238b         0         0  ...                33                 29\n",
            "2e7eeaca71         0         0  ...                60                 54\n",
            "332b911361         0         1  ...                24                 22\n",
            "c13eba9d88         0         0  ...                62                 61\n",
            "\n",
            "[140024 rows x 333 columns]\n",
            "            gender_M  gender_F  ...  brand_id_nunique  vendor_id_nunique\n",
            "client_id                       ...                                     \n",
            "353f2648f3         0         0  ...                11                  9\n",
            "f0d6002166         0         1  ...                22                 19\n",
            "af4f3039fe         0         0  ...                 7                  8\n",
            "34b4ce6c2a         0         1  ...                23                 22\n",
            "7046ea76d3         0         1  ...                22                 18\n",
            "...              ...       ...  ...               ...                ...\n",
            "d5c9592f5f         0         0  ...                67                 51\n",
            "555d2436d3         0         0  ...                29                 25\n",
            "bc21e85e6e         0         1  ...                51                 43\n",
            "aa4d24e82f         0         0  ...                47                 39\n",
            "ad18c83a2e         0         0  ...                36                 29\n",
            "\n",
            "[60011 rows x 333 columns]\n",
            "client_id\n",
            "5803624422    0.0\n",
            "0c10e0113f    0.0\n",
            "780fdce344    0.0\n",
            "562e637280    0.0\n",
            "e8c403a376    0.0\n",
            "             ... \n",
            "92b01a0cac    0.0\n",
            "6878ea0c34    0.0\n",
            "9d79650e88    0.0\n",
            "2e7eeaca71    0.0\n",
            "c13eba9d88    0.0\n",
            "Name: Z_trans, Length: 53185, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD8glUCpg9aw",
        "outputId": "b39682ca-8100-464e-f5fb-77af97fef2d0"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "Z_train_dummies = pd.get_dummies(Z_trans_train)\r\n",
        "Z_test_dummies = pd.get_dummies(Z_trans_test)\r\n",
        "\r\n",
        "print(Z_train_dummies)\r\n",
        "print(Z_test_dummies)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            0.0  1.0  2.0\n",
            "client_id                \n",
            "5803624422    1    0    0\n",
            "20b7b05f7d    0    1    0\n",
            "0c10e0113f    1    0    0\n",
            "1761677f2d    0    0    1\n",
            "aa188a0008    0    1    0\n",
            "...         ...  ...  ...\n",
            "4ef8dd16ad    0    0    1\n",
            "a54f58238b    0    0    1\n",
            "2e7eeaca71    1    0    0\n",
            "332b911361    0    0    1\n",
            "c13eba9d88    1    0    0\n",
            "\n",
            "[140024 rows x 3 columns]\n",
            "            0.0  1.0  2.0\n",
            "client_id                \n",
            "353f2648f3    1    0    0\n",
            "f0d6002166    1    0    0\n",
            "af4f3039fe    0    0    1\n",
            "34b4ce6c2a    0    0    1\n",
            "7046ea76d3    0    0    1\n",
            "...         ...  ...  ...\n",
            "d5c9592f5f    0    1    0\n",
            "555d2436d3    0    1    0\n",
            "bc21e85e6e    0    1    0\n",
            "aa4d24e82f    1    0    0\n",
            "ad18c83a2e    0    0    1\n",
            "\n",
            "[60011 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEkkrFERTR6O",
        "outputId": "d54a40ce-e333-40ae-bcae-0bc59eaa20a8"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "import numpy as np\n",
        "\n",
        "\n",
        "scaler = StandardScaler(with_std = False, with_mean = False)\n",
        "\n",
        "X_train_0 = X_train.copy()\n",
        "# X_train_0['treatment'] = 0\n",
        "\n",
        "X_train_1 = X_train.copy()\n",
        "# X_train_1['treatment'] = 1\n",
        "\n",
        "X_train_1 = X_train_1.astype('float32')\n",
        "X_train_1 = X_train_1.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_train_1 = scaler.fit_transform(X_train_1)\n",
        "\n",
        "\n",
        "\n",
        "X_train_0 = X_train_0.astype('float32')\n",
        "X_train_0 = X_train_0.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_train_0 = scaler.fit_transform(X_train_0)\n",
        "\n",
        "\n",
        "X_test_0 = X_test.copy()\n",
        "# X_test_0['treatment'] = 0\n",
        "\n",
        "X_test_1 = X_test.copy()\n",
        "# X_test_1['treatment'] = 1\n",
        "\n",
        "X_test_1 = X_test_1.astype('float32')\n",
        "X_test_1 = X_test_1.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_test_1 = scaler.fit_transform(X_test_1)\n",
        "\n",
        "X_test_0 = X_test_0.astype('float32')\n",
        "X_test_0 = X_test_0.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_test_0 = scaler.fit_transform(X_test_0)\n",
        "\n",
        "\n",
        "\n",
        "X_train_0 = np.c_[ X_train_0, np.zeros(X_train_0.shape[0]) ]\n",
        "X_train_1 = np.c_[ X_train_1, np.ones(X_train_1.shape[0]) ]\n",
        "\n",
        "X_test_0 = np.c_[ X_test_0, np.zeros(X_test_0.shape[0]) ]\n",
        "X_test_1 = np.c_[ X_test_1, np.ones(X_test_1.shape[0]) ] \n",
        "\n",
        "print(X_train_0, \"size = \", X_train_0.shape)\n",
        "print(X_train_1, \"size = \", X_train_1.shape)\n",
        "\n",
        "print(X_test_0, \"size = \", X_test_0.shape)\n",
        "print(X_test_1, \"size = \", X_test_1.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.  0.  1. ... 26. 20.  0.]\n",
            " [ 1.  0.  0. ... 54. 42.  0.]\n",
            " [ 0.  0.  1. ... 41. 31.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ... 60. 54.  0.]\n",
            " [ 0.  1.  0. ... 24. 22.  0.]\n",
            " [ 0.  0.  1. ... 62. 61.  0.]] size =  (140024, 334)\n",
            "[[ 0.  0.  1. ... 26. 20.  1.]\n",
            " [ 1.  0.  0. ... 54. 42.  1.]\n",
            " [ 0.  0.  1. ... 41. 31.  1.]\n",
            " ...\n",
            " [ 0.  0.  1. ... 60. 54.  1.]\n",
            " [ 0.  1.  0. ... 24. 22.  1.]\n",
            " [ 0.  0.  1. ... 62. 61.  1.]] size =  (140024, 334)\n",
            "[[ 0.  0.  1. ... 11.  9.  0.]\n",
            " [ 0.  1.  0. ... 22. 19.  0.]\n",
            " [ 0.  0.  1. ...  7.  8.  0.]\n",
            " ...\n",
            " [ 0.  1.  0. ... 51. 43.  0.]\n",
            " [ 0.  0.  1. ... 47. 39.  0.]\n",
            " [ 0.  0.  1. ... 36. 29.  0.]] size =  (60011, 334)\n",
            "[[ 0.  0.  1. ... 11.  9.  1.]\n",
            " [ 0.  1.  0. ... 22. 19.  1.]\n",
            " [ 0.  0.  1. ...  7.  8.  1.]\n",
            " ...\n",
            " [ 0.  1.  0. ... 51. 43.  1.]\n",
            " [ 0.  0.  1. ... 47. 39.  1.]\n",
            " [ 0.  0.  1. ... 36. 29.  1.]] size =  (60011, 334)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCR8UhfJt3eI"
      },
      "source": [
        "class trainData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data_0,X_data_1,Z_trans,treatment, y_data):\n",
        "        self.X_data_0 = X_data_0\n",
        "        self.X_data_1 = X_data_1\n",
        "        self.Z_trans = Z_trans\n",
        "        self.treatment = treatment\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data_0[index], self.X_data_1[index],self.Z_trans[index], self.treatment[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data_0)\n",
        "\n",
        "\n",
        "train_data = trainData(torch.FloatTensor(X_train_0),torch.FloatTensor(X_train_1),torch.FloatTensor(Z_trans_train),torch.FloatTensor(treatment_train), \n",
        "                       torch.FloatTensor(y_train))\n",
        "## test data    \n",
        "\n",
        "class testData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data_0,X_data_1,Z_trans,treatment,y_data):\n",
        "        self.X_data_0 = X_data_0\n",
        "        self.X_data_1 = X_data_1\n",
        "        self.Z_trans = Z_trans\n",
        "        self.treatment = treatment\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data_0[index], self.X_data_1[index],self.Z_trans[index], self.treatment[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data_0)\n",
        "    \n",
        "\n",
        "test_data = testData(torch.FloatTensor(X_test_0),torch.FloatTensor(X_test_1), torch.FloatTensor(Z_trans_test),torch.FloatTensor(treatment_test), \n",
        "                       torch.FloatTensor(y_test))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QFze6m8QwSX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pylab\n",
        "\n",
        "  \n",
        "from sklearn.utils.validation import check_consistent_length\n",
        "\n",
        "\n",
        "\n",
        "def plot_qini_curve(y_reactions, uplift_score, treatment, random=True, perfect=True):\n",
        "    \"\"\"Plot Qini curves from predictions.\"\"\"\n",
        "   \n",
        "    check_consistent_length(y_reactions, uplift_score, treatment)\n",
        "    y_reactions, uplift_score, treatment = np.array(y_reactions), np.array(uplift_score), np.array(treatment)\n",
        "\n",
        "   \n",
        "\n",
        "    x_actual, y_actual = qini_curve(y_reactions, uplift_score, treatment)\n",
        "\n",
        "    pylab.plot(x_actual, y_actual, label='Our model', color='green')\n",
        "    if random:\n",
        "        x_baseline, y_baseline = x_actual, x_actual * y_actual[-1] / len(y_reactions)\n",
        "        pylab.plot(x_baseline, y_baseline, label='Random model', color='black')\n",
        "        \n",
        "\n",
        "    if perfect:\n",
        "        x_perfect, y_perfect = perfect_qini_curve(y_reactions, treatment)\n",
        "        # print(\"1 point\", x_perfect[1], y_perfect[1])\n",
        "        # print(\"2 point\", x_perfect[2], y_perfect[2])\n",
        "        # print(\"3 point\", x_perfect[3], y_perfect[3])\n",
        "        pylab.plot(x_perfect, y_perfect, label='Perfect model', color='Red')\n",
        "        \n",
        "    #pylab.fill_between(x_perfect, y_baseline, y_perfect, color=\"blue\")\n",
        "    pylab.grid(True)\n",
        "    pylab.xlabel('Treat num')\n",
        "    pylab.ylabel('Uplift reactions')\n",
        "    pylab.title('Qini curve')\n",
        "    pylab.legend(loc='lower right')\n",
        "    return pylab\n",
        "\n",
        "\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpZxmbiJjDFZ"
      },
      "source": [
        "cross entropy with Z_dummies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BDc2stYwjCzO",
        "outputId": "49bb5e8b-485b-4c16-aef5-769656573bec"
      },
      "source": [
        "import torch\r\n",
        "from torch.autograd import Variable\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import torch.optim as optim\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from statistics import mean\r\n",
        "\r\n",
        "batch_size = 35006   # Number of samples in each batch\r\n",
        "batch_size_test=7 #7\r\n",
        "epoch_num = 19  # Number of epochs to train the network  to do try more epochs\r\n",
        "lr = 0.001        # Learning rate\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class Model(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Model, self).__init__()\r\n",
        "        self.fc1 = nn.Linear(334, 200)\r\n",
        "        self.fc2 = nn.Linear(200, 100)\r\n",
        "        self.fc3 = nn.Linear(100, 3)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        \r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        m = nn.Softmax()\r\n",
        "        return m(x)\r\n",
        "        \r\n",
        "\r\n",
        "model = Model()\r\n",
        "alpha = 1.0\r\n",
        "\r\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "# print(device)\r\n",
        "# model.to(device)\r\n",
        "# print(model)\r\n",
        "\r\n",
        "\r\n",
        "# #convert to torch structure\r\n",
        "# X_test_1_tensor = torch.FloatTensor(X_test_1) \r\n",
        "# X_test_0_tensor = torch.FloatTensor(X_test_0)\r\n",
        "\r\n",
        "\r\n",
        "# #convert to torch structure\r\n",
        "# treatment_test = treatment_test.to_numpy()\r\n",
        "# treatment_test = torch.from_numpy(treatment_test).int()\r\n",
        "# treatment_test = Variable(treatment_test)\r\n",
        "\r\n",
        "\r\n",
        "# #convert to torch structure\r\n",
        "# y_test = y_test.to_numpy()\r\n",
        "# y_test = torch.from_numpy(y_test).float()\r\n",
        "# y_test  = Variable(y_test)\r\n",
        "\r\n",
        "\r\n",
        "# #convert to torch structure\r\n",
        "# Z_trans_test = Z_trans_test.to_numpy()\r\n",
        "# Z_trans_test = torch.from_numpy(Z_trans_test).float()\r\n",
        "# Z_trans_test = Variable(Z_trans_test)\r\n",
        "\r\n",
        "\r\n",
        "#init loaders\r\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\r\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=batch_size_test, shuffle=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# define the loss (criterion) and create an optimizer\r\n",
        "optimizer = optim.Adam(model.parameters())\r\n",
        "\r\n",
        "# define lists of losses to store\r\n",
        "all_losses  = []\r\n",
        "test_losses = []\r\n",
        "min_losses = []\r\n",
        "\r\n",
        "\r\n",
        "model.train()\r\n",
        "# epochs loop\r\n",
        "for ep in range(epoch_num):  \r\n",
        "    print(\".......................... epoch =\",ep,\"..........................\")\r\n",
        "    batch_loss = []\r\n",
        "    # batches loop\r\n",
        "    for X_batch_0,X_batch_1,Z_batch,treatment_batch, y_batch in train_loader:\r\n",
        "       \r\n",
        "       \r\n",
        "        \r\n",
        "        batch_1_feat = X_batch_1\r\n",
        "        batch_0_feat = X_batch_0\r\n",
        "        \r\n",
        "        batch_label = y_batch\r\n",
        "        batch_Z_trans = Z_batch\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        # Forward pass (predict)\r\n",
        "        mu_1_target_class = model(batch_1_feat)\r\n",
        "        mu_0_target_class = model(batch_0_feat)\r\n",
        "\r\n",
        "        #convert to torch structure\r\n",
        "        treatment_batch = treatment_batch\r\n",
        "       \r\n",
        "\r\n",
        "        # mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\r\n",
        "        # mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\r\n",
        "        \r\n",
        "     \r\n",
        "\r\n",
        "\r\n",
        "       \r\n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\r\n",
        "        # uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "        \r\n",
        "       \r\n",
        "\r\n",
        "       \r\n",
        "        \r\n",
        "        \r\n",
        "        #declare losses\r\n",
        "        loss_cross = nn.CrossEntropyLoss()\r\n",
        "      \r\n",
        "\r\n",
        "        #implements uplift_predicted = mu_1 - mu_0\r\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \r\n",
        "        \r\n",
        "        # Z_trans_train = torch.Tensor(Z_batch) \r\n",
        "        # Z_dummies = torch.nn.functional.one_hot(Z_trans_train.to(torch.int64), num_classes = 3)\r\n",
        "\r\n",
        "        Z_trans_train = Z_batch.to(torch.int64)\r\n",
        "        print(\"Z_train\",Z_trans_train)\r\n",
        "\r\n",
        "        pred_uplift = mu_1_target_class - mu_0_target_class\r\n",
        "        print(\"uplift_pred\", pred_uplift)\r\n",
        "\r\n",
        "       \r\n",
        "        \r\n",
        "\r\n",
        "        sum_of_losses = torch.mean(  loss_cross(mu_1_target_class-mu_0_target_class,Z_trans_train) )\r\n",
        "        # print(loss_contrastive)\r\n",
        "        batch_loss.append(sum_of_losses)\r\n",
        "        # print(\"train AUQC:\", qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "\r\n",
        "        \r\n",
        "        # print(batch_n, loss_contrastive)\r\n",
        "\r\n",
        "\r\n",
        "        # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\r\n",
        "        # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "        \r\n",
        "        # Backward pass and updates\r\n",
        "        sum_of_losses.backward()                     # calculate the gradients\r\n",
        "        optimizer.step()                    # update the weights\r\n",
        "        # i += batch_size\r\n",
        "        #end for !!!!!!!!!!!!!!!!!!!\r\n",
        "\r\n",
        "    # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\r\n",
        "    # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "    batch_loss  = list(batch_loss)\r\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss) ) \r\n",
        "\r\n",
        "    # # #work with test dataset\r\n",
        "    # print('work with test dataset')\r\n",
        "    # batch_loss = []\r\n",
        "    # for X_batch_0,X_batch_1,Z_batch,treatment_batch, y_batch in test_loader:\r\n",
        "        \r\n",
        "       \r\n",
        "        \r\n",
        "    #     batch_1_feat = X_batch_1\r\n",
        "    #     batch_0_feat = X_batch_0\r\n",
        "        \r\n",
        "    #     batch_label = y_batch\r\n",
        "    #     batch_Z_trans = Z_batch\r\n",
        "\r\n",
        "    #     optimizer.zero_grad()\r\n",
        "    #     # Forward pass (predict)\r\n",
        "    #     mu_1_target_class = model(batch_1_feat)\r\n",
        "    #     mu_0_target_class = model(batch_0_feat)\r\n",
        "\r\n",
        "       \r\n",
        "       \r\n",
        "\r\n",
        "    #     # mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\r\n",
        "    #     # mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\r\n",
        "        \r\n",
        "    #     # print(\"mu_0\", mu_0_target_class)\r\n",
        "    #     # print(\"mu_1\", mu_1_target_class)\r\n",
        "\r\n",
        "    #     ones = np.ones(shape = batch_size_test)\r\n",
        "    #     ones = torch.from_numpy(ones).float()\r\n",
        "        \r\n",
        "     \r\n",
        "    #     #implements mu = T * mu_1 + (1-T) * mu_0\r\n",
        "    #     uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \r\n",
        "\r\n",
        "    #     #declare losses\r\n",
        "    #     loss_cross = nn.BCELoss(reduction = 'mean')\r\n",
        "    #     loss_MSE = nn.MSELoss()\r\n",
        "\r\n",
        "    #     #implements uplift_predicted = mu_1 - mu_0\r\n",
        "    #     uplift_pred = mu_1_target_class - mu_0_target_class   \r\n",
        "\r\n",
        "    #     sum_of_losses = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\r\n",
        "       \r\n",
        "    #     batch_loss.append(sum_of_losses)\r\n",
        "        \r\n",
        "\r\n",
        "        \r\n",
        "    #     # print(batch_n, loss_contrastive)\r\n",
        "\r\n",
        "\r\n",
        "    #     # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\r\n",
        "    #     # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        #end for\r\n",
        "    # batch_loss  = list(batch_loss)\r\n",
        "    # test_losses.append( sum(batch_loss) / len(batch_loss) ) \r\n",
        "    \r\n",
        "\r\n",
        "    \r\n",
        "   \r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(all_losses, color='green',label='train')\r\n",
        "plt.title('train vs test')\r\n",
        "plt.xlabel('epoch_num')\r\n",
        "plt.ylabel('loss sum')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# plt.plot(test_losses, color='blue',label='test')\r\n",
        "# plt.legend()\r\n",
        "\r\n",
        "\r\n",
        "# plt.show()\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".......................... epoch = 0 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Z_train tensor([0, 0, 2,  ..., 2, 2, 2])\n",
            "uplift_pred tensor([[ 3.5501e-04, -3.5504e-04,  0.0000e+00],\n",
            "        [ 4.5896e-06, -4.6007e-06,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 2.9667e-06, -2.9802e-06, -1.0733e-41],\n",
            "        [ 2.9206e-06, -2.8796e-06, -6.4862e-30],\n",
            "        [-2.1059e-04,  2.1058e-04,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 0, 2,  ..., 2, 2, 0])\n",
            "uplift_pred tensor([[ 1.0759e-25,  0.0000e+00, -4.2308e-41],\n",
            "        [ 1.5641e-27,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.3574e-14,  0.0000e+00, -2.6583e-34],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 0, 2,  ..., 1, 0, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 4.0818e-24,  0.0000e+00, -5.1593e-32],\n",
            "        [ 2.7031e-34,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 9.1222e-36,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.3989e-34,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 0, 1,  ..., 2, 2, 2])\n",
            "uplift_pred tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [7.7231e-40, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 1 ..........................\n",
            "Z_train tensor([1, 1, 0,  ..., 0, 0, 1])\n",
            "uplift_pred tensor([[1.9079e-19, 0.0000e+00, 2.9946e-31],\n",
            "        [8.6914e-38, 0.0000e+00, 0.0000e+00],\n",
            "        [4.3095e-25, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [3.0102e-38, 0.0000e+00, 0.0000e+00],\n",
            "        [3.8738e-24, 0.0000e+00, 5.2689e-43],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 0, 2,  ..., 1, 0, 1])\n",
            "uplift_pred tensor([[ 1.3553e-30,  0.0000e+00, -6.1475e-41],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 1.4584e-32,  0.0000e+00,  3.1445e-42],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 0, 1,  ..., 2, 0, 1])\n",
            "uplift_pred tensor([[2.3779e-20, 0.0000e+00, 8.1576e-27],\n",
            "        [4.0626e-11, 0.0000e+00, 1.0175e-18],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [9.8196e-35, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 0, 1,  ..., 0, 2, 2])\n",
            "uplift_pred tensor([[3.2601e-23, 0.0000e+00, 2.7035e-34],\n",
            "        [3.5868e-14, 0.0000e+00, 1.2743e-28],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [1.2783e-24, 0.0000e+00, 5.6425e-40],\n",
            "        [1.9075e-38, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 2 ..........................\n",
            "Z_train tensor([0, 0, 0,  ..., 2, 1, 1])\n",
            "uplift_pred tensor([[3.1161e-36, 0.0000e+00, 0.0000e+00],\n",
            "        [1.9614e-19, 0.0000e+00, 3.8356e-36],\n",
            "        [1.1914e-31, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [7.8775e-34, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [7.4809e-09, 0.0000e+00, 1.9389e-23]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 2, 1,  ..., 1, 2, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.2898e-18,  0.0000e+00,  1.7981e-31],\n",
            "        ...,\n",
            "        [ 2.8762e-34,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 5.4688e-03, -5.4688e-03, -1.6541e-18]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 1, 1,  ..., 1, 0, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00, -2.5065e-13, -9.5425e-17],\n",
            "        [ 1.4013e-45,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 2.1264e-38,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 1, 0,  ..., 0, 2, 2])\n",
            "uplift_pred tensor([[3.3757e-10, 0.0000e+00, 7.9810e-29],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [1.2677e-26, 0.0000e+00, 0.0000e+00],\n",
            "        [4.4253e-42, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 3 ..........................\n",
            "Z_train tensor([0, 1, 0,  ..., 0, 0, 2])\n",
            "uplift_pred tensor([[ 5.0383e-13,  0.0000e+00,  0.0000e+00],\n",
            "        [ 5.1083e-06, -5.0068e-06,  1.6947e-39],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 1.5385e-24,  0.0000e+00,  0.0000e+00],\n",
            "        [ 3.0696e-03, -3.0697e-03,  0.0000e+00],\n",
            "        [ 1.6190e-40,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 2, 0,  ..., 0, 0, 0])\n",
            "uplift_pred tensor([[ 2.6048e-16,  0.0000e+00,  0.0000e+00],\n",
            "        [ 4.7392e-40,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.9446e-18,  0.0000e+00,  6.5861e-44],\n",
            "        ...,\n",
            "        [ 6.0692e-27,  0.0000e+00,  0.0000e+00],\n",
            "        [ 5.5374e-41,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -2.6655e-08, -1.9548e-40]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 1, 1,  ..., 2, 0, 2])\n",
            "uplift_pred tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [4.4456e-29, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.2831e-20, 0.0000e+00, 3.4111e-35],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 2, 1,  ..., 2, 1, 2])\n",
            "uplift_pred tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [6.1497e-13, 0.0000e+00, 6.5385e-22],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 4 ..........................\n",
            "Z_train tensor([1, 2, 0,  ..., 2, 1, 0])\n",
            "uplift_pred tensor([[ 1.1185e-04, -1.1188e-04,  3.9085e-33],\n",
            "        [ 4.0769e-20,  0.0000e+00,  1.4013e-45],\n",
            "        [ 1.4158e-03, -1.4158e-03,  1.1112e-25],\n",
            "        ...,\n",
            "        [ 3.8458e-06, -3.8147e-06,  1.4502e-19],\n",
            "        [ 3.7258e-16,  0.0000e+00,  1.4487e-36],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 1, 1,  ..., 2, 1, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00, -5.9146e-18,  0.0000e+00],\n",
            "        [ 0.0000e+00, -9.6617e-25, -5.9443e-42],\n",
            "        [ 2.7418e-06, -2.6698e-06, -3.9328e-32],\n",
            "        ...,\n",
            "        [ 5.3716e-04, -5.3709e-04, -1.4507e-20],\n",
            "        [ 2.4145e-14,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.3452e-43,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 2, 1,  ..., 0, 1, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -4.6632e-15,  0.0000e+00],\n",
            "        [ 7.7673e-38,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 2.3956e-21,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.6795e-27,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.2988e-04, -6.4760e-05, -6.5181e-05]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 2, 1,  ..., 0, 1, 0])\n",
            "uplift_pred tensor([[ 4.0411e-03, -4.0411e-03, -8.8221e-25],\n",
            "        [ 1.7899e-13,  0.0000e+00,  6.5847e-41],\n",
            "        [ 4.5591e-10,  0.0000e+00,  1.1476e-22],\n",
            "        ...,\n",
            "        [ 2.3598e-23,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.1683e-02, -1.1683e-02, -2.4249e-09]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 5 ..........................\n",
            "Z_train tensor([1, 1, 2,  ..., 1, 2, 1])\n",
            "uplift_pred tensor([[5.6933e-29, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0141e-09, 0.0000e+00, 2.0113e-25],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [1.2796e-10, 0.0000e+00, 1.1703e-26],\n",
            "        [1.1467e-32, 0.0000e+00, 0.0000e+00],\n",
            "        [7.1009e-13, 0.0000e+00, 4.1520e-39]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 2, 0,  ..., 0, 2, 0])\n",
            "uplift_pred tensor([[ 1.7329e-18,  0.0000e+00,  5.0444e-39],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.5708e-07, -2.3842e-07,  1.9221e-26],\n",
            "        ...,\n",
            "        [ 3.0210e-03, -3.0209e-03,  1.5828e-10],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 2.6609e-12,  0.0000e+00,  9.0715e-24]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 2, 1,  ..., 2, 2, 1])\n",
            "uplift_pred tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [6.2915e-25, 0.0000e+00, 2.8026e-45],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 0, 0,  ..., 0, 0, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 2.9796e-04, -2.9793e-04, -2.8906e-20],\n",
            "        [ 7.2237e-42,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 1.1249e-03, -1.1247e-03,  2.7087e-18],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 4.6257e-37,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 6 ..........................\n",
            "Z_train tensor([1, 2, 2,  ..., 2, 1, 2])\n",
            "uplift_pred tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 2, 2,  ..., 2, 2, 1])\n",
            "uplift_pred tensor([[2.2072e-29, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 0, 1,  ..., 2, 1, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 3.5287e-21,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 1.2024e-15,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.4073e-06, -1.4305e-06,  1.6479e-33]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 1, 0,  ..., 1, 0, 1])\n",
            "uplift_pred tensor([[ 2.3347e-25,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.7589e-04, -1.7589e-04,  5.9892e-17],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 7 ..........................\n",
            "Z_train tensor([0, 0, 2,  ..., 0, 1, 0])\n",
            "uplift_pred tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [4.4435e-16, 0.0000e+00, 2.5574e-35],\n",
            "        [3.3178e-23, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 1, 0,  ..., 1, 1, 2])\n",
            "uplift_pred tensor([[7.8422e-31, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.3259e-15, 0.0000e+00, 4.5544e-38],\n",
            "        ...,\n",
            "        [1.0679e-26, 0.0000e+00, 0.0000e+00],\n",
            "        [1.5823e-39, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 2, 2,  ..., 2, 0, 1])\n",
            "uplift_pred tensor([[4.6250e-08, 0.0000e+00, 4.0738e-33],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [3.6291e-39, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [8.5039e-16, 0.0000e+00, 1.8516e-39],\n",
            "        [2.1071e-37, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 1, 1,  ..., 0, 1, 2])\n",
            "uplift_pred tensor([[ 3.6365e-38,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.0459e-09,  0.0000e+00,  1.6942e-39],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 1.5447e-02, -1.5447e-02, -2.7025e-24],\n",
            "        [ 5.4470e-28,  0.0000e+00,  0.0000e+00],\n",
            "        [ 4.2039e-45,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 8 ..........................\n",
            "Z_train tensor([0, 0, 0,  ..., 2, 0, 2])\n",
            "uplift_pred tensor([[ 1.8061e-02, -1.8061e-02,  0.0000e+00],\n",
            "        [ 3.3966e-07, -3.5763e-07,  0.0000e+00],\n",
            "        [ 3.6846e-02, -3.6846e-02,  2.3642e-19],\n",
            "        ...,\n",
            "        [ 8.8291e-05, -8.8274e-05,  8.2906e-26],\n",
            "        [ 1.9363e-15,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 0, 1,  ..., 1, 2, 0])\n",
            "uplift_pred tensor([[ 3.7726e-27,  0.0000e+00,  0.0000e+00],\n",
            "        [ 2.1506e-09,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.7661e-26,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 2.2020e-10,  0.0000e+00,  0.0000e+00],\n",
            "        [ 1.0136e-02, -1.0136e-02,  1.5635e-35],\n",
            "        [ 9.4605e-03, -9.4604e-03,  4.5228e-08]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 1, 2,  ..., 2, 1, 1])\n",
            "uplift_pred tensor([[ 7.8879e-17,  0.0000e+00,  0.0000e+00],\n",
            "        [ 3.4294e-07, -3.5763e-07,  4.2601e-36],\n",
            "        [ 3.6633e-16,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 4.1405e-14,  0.0000e+00,  0.0000e+00],\n",
            "        [ 2.3691e-12,  0.0000e+00,  0.0000e+00],\n",
            "        [ 2.2616e-24,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 0, 1,  ..., 0, 0, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 2.6428e-02, -2.6429e-02,  7.3274e-07],\n",
            "        [ 3.5763e-07, -3.9557e-07,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 4.6413e-03, -4.6413e-03, -3.3412e-19],\n",
            "        [ 0.0000e+00, -5.2369e-11,  0.0000e+00],\n",
            "        [ 0.0000e+00, -1.1128e-14,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 9 ..........................\n",
            "Z_train tensor([2, 2, 2,  ..., 2, 0, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00, -2.8130e-16, -2.1754e-37],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -6.3835e-36,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -4.3172e-28,  0.0000e+00],\n",
            "        [ 0.0000e+00, -8.1763e-14, -1.4137e-28],\n",
            "        [ 0.0000e+00, -1.2998e-40,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 1, 0,  ..., 0, 2, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -3.5048e-41,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 1, 0,  ..., 0, 2, 0])\n",
            "uplift_pred tensor([[ 1.9670e-05, -1.9629e-05, -1.4604e-21],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -1.5834e-19, -9.9979e-26],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -5.2049e-18, -1.2309e-25],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 0, 0,  ..., 0, 1, 2])\n",
            "uplift_pred tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 10 ..........................\n",
            "Z_train tensor([1, 0, 1,  ..., 1, 1, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -2.8026e-45,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -1.4013e-45,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 2, 1,  ..., 0, 2, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00, -2.4290e-41, -1.4013e-45],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -1.9253e-28, -9.7357e-27]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 2, 2,  ..., 0, 1, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -7.2174e-17, -4.6259e-19]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 0, 1,  ..., 0, 0, 0])\n",
            "uplift_pred tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 11 ..........................\n",
            "Z_train tensor([0, 2, 0,  ..., 2, 0, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00, -1.4826e-41]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 2, 2,  ..., 0, 1, 2])\n",
            "uplift_pred tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 1, 1,  ..., 1, 0, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00, -4.5668e-42],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 1, 0,  ..., 0, 2, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -2.6917e-39, -2.4134e-36],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 12 ..........................\n",
            "Z_train tensor([0, 2, 2,  ..., 0, 2, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -2.1708e-26, -1.3248e-20],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -8.9957e-28, -2.3498e-23],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 2, 0,  ..., 1, 1, 1])\n",
            "uplift_pred tensor([[ 1.1059e-06, -1.0729e-06,  1.3361e-13],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 0, 2,  ..., 0, 0, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 2.2906e-04, -2.2912e-04,  1.8428e-12],\n",
            "        [ 0.0000e+00, -2.3738e-42, -1.5414e-44]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 0, 1,  ..., 1, 0, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00, -3.8418e-28, -1.1632e-37],\n",
            "        [ 0.0000e+00, -3.8487e-38, -2.1175e-41],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -1.2107e-41, -7.1004e-42],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 13 ..........................\n",
            "Z_train tensor([1, 2, 2,  ..., 1, 2, 2])\n",
            "uplift_pred tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 1, 2,  ..., 0, 1, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00, -9.5018e-36, -3.6050e-39],\n",
            "        [ 0.0000e+00, -2.5136e-39, -7.2266e-37],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00, -1.4170e-41]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 0, 0,  ..., 1, 2, 2])\n",
            "uplift_pred tensor([[ 9.5378e-39,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00, -2.1099e-39],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 1, 2,  ..., 2, 1, 2])\n",
            "uplift_pred tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 14 ..........................\n",
            "Z_train tensor([0, 0, 2,  ..., 0, 0, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 5.8900e-03, -5.8900e-03, -8.5426e-21],\n",
            "        ...,\n",
            "        [ 4.9726e-17,  0.0000e+00,  2.9060e-14],\n",
            "        [ 0.0000e+00,  0.0000e+00, -5.6052e-45],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 2, 2,  ..., 2, 2, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 8.6948e-05, -2.3258e-04,  1.4556e-04],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 0, 0,  ..., 1, 0, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -1.5709e-11, -1.8332e-14],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -1.8908e-12, -4.0026e-18],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -7.7109e-22, -1.5612e-25]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 2, 0,  ..., 2, 0, 0])\n",
            "uplift_pred tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 15 ..........................\n",
            "Z_train tensor([2, 2, 2,  ..., 0, 1, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00, -2.6317e-32, -6.1855e-37],\n",
            "        [ 0.0000e+00,  0.0000e+00, -1.4906e-41],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -8.5840e-33, -8.9661e-31],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 1, 0,  ..., 1, 0, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -1.2060e-32, -1.8207e-41],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -7.2118e-15, -1.1705e-19]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 1, 0,  ..., 2, 1, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 5.9605e-07, -5.2633e-07, -3.7305e-15],\n",
            "        [ 3.8662e-11,  0.0000e+00,  2.1239e-15],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 2, 2,  ..., 0, 0, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -6.3800e-39, -1.5733e-31],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -2.8594e-24, -6.0736e-27],\n",
            "        [ 5.0364e-02, -5.0364e-02,  6.8378e-10],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 16 ..........................\n",
            "Z_train tensor([2, 1, 2,  ..., 0, 1, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00, -5.6052e-45],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 4.2592e-07, -4.7684e-07,  5.0353e-26],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 1, 2,  ..., 1, 2, 0])\n",
            "uplift_pred tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        ...,\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [3.0473e-34, 0.0000e+00, 1.4734e-31]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 1, 0,  ..., 0, 1, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00, -6.0856e-23, -7.3126e-29],\n",
            "        [ 4.7065e-09,  0.0000e+00,  1.0808e-19],\n",
            "        [ 3.5763e-07, -4.5038e-07, -2.1764e-13],\n",
            "        ...,\n",
            "        [ 3.7940e-14,  0.0000e+00,  7.2406e-27],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 1, 0,  ..., 1, 2, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -9.1325e-09, -1.6488e-10],\n",
            "        ...,\n",
            "        [ 3.6156e-04, -3.6157e-04, -4.7644e-44],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -1.2458e-40, -1.3384e-41]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 17 ..........................\n",
            "Z_train tensor([1, 0, 0,  ..., 2, 2, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -2.2250e-22, -2.0276e-21],\n",
            "        [ 2.6404e-06, -2.6226e-06,  8.9171e-11],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -2.8637e-39, -4.9405e-36],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 1, 2,  ..., 1, 0, 1])\n",
            "uplift_pred tensor([[ 6.9141e-06, -6.9181e-06, -1.2481e-32],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -6.7981e-18, -4.3663e-21]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 1, 1,  ..., 2, 0, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -6.7688e-29, -4.0638e-44],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([1, 2, 2,  ..., 0, 1, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -8.1345e-18, -3.8469e-20],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -5.8580e-40, -2.7928e-42]], grad_fn=<SubBackward0>)\n",
            ".......................... epoch = 18 ..........................\n",
            "Z_train tensor([2, 2, 2,  ..., 0, 0, 1])\n",
            "uplift_pred tensor([[ 7.7772e-02, -7.7772e-02, -5.7808e-25],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 1.3681e-13,  0.0000e+00,  4.8260e-14],\n",
            "        [ 0.0000e+00, -1.4530e-30, -4.6270e-28],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 1, 1,  ..., 1, 1, 0])\n",
            "uplift_pred tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00, -9.8091e-45, -1.4013e-45],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 6.1596e-20,  0.0000e+00,  1.2073e-33]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([0, 2, 2,  ..., 2, 0, 1])\n",
            "uplift_pred tensor([[ 0.0000e+00, -4.6243e-44, -7.0065e-45],\n",
            "        [ 0.0000e+00, -2.2258e-31,  0.0000e+00],\n",
            "        [ 0.0000e+00, -8.7818e-36, -7.0065e-45],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 3.1114e-05, -3.0966e-05, -3.8000e-08]], grad_fn=<SubBackward0>)\n",
            "Z_train tensor([2, 2, 1,  ..., 0, 0, 2])\n",
            "uplift_pred tensor([[ 0.0000e+00, -4.2491e-20,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss sum')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpE-aifRxgCD",
        "outputId": "ae7dfe7b-2243-43fc-8a5d-99555469806d"
      },
      "source": [
        "model.eval()\r\n",
        "pred0=model(torch.FloatTensor(X_train_0))\r\n",
        "pred1=model(torch.FloatTensor(X_train_1))\r\n",
        "\r\n",
        "# print(treatment_train[6])\r\n",
        "# print(y_train[6])\r\n",
        "\r\n",
        "pred_uplift = (pred1-pred0).cpu().detach().numpy() \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(\"max\", np.max(pred_uplift))\r\n",
        "print(\"min\", np.min(pred_uplift))\r\n",
        "\r\n",
        "\r\n",
        "print(pred_uplift[200:250])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max 0.08126339\n",
            "min -0.08126342\n",
            "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 2.2411346e-05 -2.2347012e-05 -2.0004250e-22]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00 -4.1231806e-41  0.0000000e+00]\n",
            " [ 2.9485715e-34  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00 -1.4012985e-45  0.0000000e+00]\n",
            " [ 0.0000000e+00 -5.7481197e-22 -3.9572669e-42]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 7.7835339e-06 -7.7486038e-06  2.6556181e-21]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 2.1295699e-18  0.0000000e+00  8.4368114e-14]\n",
            " [ 0.0000000e+00  0.0000000e+00  2.8755774e-37]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00 -3.2785059e-27 -8.1517483e-30]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 1.4012985e-45  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  3.3801942e-38]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 4.4427868e-03 -4.4428110e-03  4.8561843e-10]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 3.2413719e-36  0.0000000e+00  2.5260546e-38]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 5.7344019e-02 -5.7344019e-02  9.8350967e-22]\n",
            " [ 0.0000000e+00 -1.8309391e-24 -2.7267286e-30]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 2.7622213e-13  0.0000000e+00  4.1970853e-21]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00 -2.3092957e-32 -5.7453237e-44]\n",
            " [ 9.5367432e-07 -1.0280751e-06  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 1.2040138e-04 -1.2049830e-04 -3.0334684e-24]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 2.2138474e-03 -2.2139549e-03  1.2439229e-15]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 1.5201243e-24  0.0000000e+00  1.8124001e-30]\n",
            " [ 0.0000000e+00 -1.5586838e-15 -5.4227435e-23]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00 -1.9526217e-37  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00 -9.9072001e-11 -1.2024981e-18]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00 -1.0930128e-42  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 2.4940729e-02 -2.4940729e-02  2.6155984e-09]\n",
            " [ 0.0000000e+00 -8.5806174e-16 -4.7003749e-35]\n",
            " [ 0.0000000e+00 -5.5818740e-38 -4.7644148e-44]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxf52gsqYnIF"
      },
      "source": [
        "neural network with dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "D26MHedEYmpz",
        "outputId": "d2b81c78-7f22-44c3-cf82-b1ee4c284c64"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 35006   # Number of samples in each batch to do(/9)\n",
        "batch_size_test=7 #7\n",
        "epoch_num = 9  # Number of epochs to train the network\n",
        "lr = 0.001        # Learning rate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 100)\n",
        "        self.fc3 = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        m = nn.Sigmoid()\n",
        "        return m(x)\n",
        "        \n",
        "\n",
        "model = Model()\n",
        "alpha = 1.0\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)\n",
        "# model.to(device)\n",
        "# print(model)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# X_test_1_tensor = torch.FloatTensor(X_test_1) \n",
        "# X_test_0_tensor = torch.FloatTensor(X_test_0)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# treatment_test = treatment_test.to_numpy()\n",
        "# treatment_test = torch.from_numpy(treatment_test).int()\n",
        "# treatment_test = Variable(treatment_test)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# y_test = y_test.to_numpy()\n",
        "# y_test = torch.from_numpy(y_test).float()\n",
        "# y_test  = Variable(y_test)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# Z_trans_test = Z_trans_test.to_numpy()\n",
        "# Z_trans_test = torch.from_numpy(Z_trans_test).float()\n",
        "# Z_trans_test = Variable(Z_trans_test)\n",
        "\n",
        "\n",
        "#init loaders\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=batch_size_test, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# define lists of losses to store\n",
        "all_losses  = []\n",
        "test_losses = []\n",
        "min_losses = []\n",
        "\n",
        "\n",
        "model.train()\n",
        "# epochs loop\n",
        "for ep in range(epoch_num):  \n",
        "    print(\".......................... epoch =\",ep,\"..........................\")\n",
        "    batch_loss = []\n",
        "    # batches loop\n",
        "    for X_batch_0,X_batch_1,Z_batch,treatment_batch, y_batch in train_loader:\n",
        "       \n",
        "       \n",
        "        \n",
        "        batch_1_feat = X_batch_1\n",
        "        batch_0_feat = X_batch_0\n",
        "        \n",
        "        batch_label = y_batch\n",
        "        batch_Z_trans = Z_batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass (predict)\n",
        "        mu_1_target_class = model(batch_1_feat)\n",
        "        mu_0_target_class = model(batch_0_feat)\n",
        "\n",
        "        #convert to torch structure\n",
        "        treatment_batch = treatment_batch\n",
        "       \n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\n",
        "        \n",
        "        # print(\"mu_0\", mu_0_target_class)\n",
        "        # print(\"mu_1\", mu_1_target_class)\n",
        "\n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        \n",
        "\n",
        "       \n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "       \n",
        "\n",
        "       \n",
        "        \n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'mean')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "        \n",
        "        \n",
        "        # print(\"uplift_pred\", uplift_pred)\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "        sum_of_losses = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "        # print(loss_contrastive)\n",
        "        batch_loss.append(sum_of_losses)\n",
        "        # print(\"train AUQC:\", qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\n",
        "        # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "        \n",
        "        # Backward pass and updates\n",
        "        sum_of_losses.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        # i += batch_size\n",
        "        #end for !!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\n",
        "    print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss) ) \n",
        "\n",
        "    # #work with test dataset\n",
        "    print('work with test dataset')\n",
        "    batch_loss = []\n",
        "    for X_batch_0,X_batch_1,Z_batch,treatment_batch, y_batch in test_loader:\n",
        "        \n",
        "       \n",
        "        \n",
        "        batch_1_feat = X_batch_1\n",
        "        batch_0_feat = X_batch_0\n",
        "        \n",
        "        batch_label = y_batch\n",
        "        batch_Z_trans = Z_batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass (predict)\n",
        "        mu_1_target_class = model(batch_1_feat)\n",
        "        mu_0_target_class = model(batch_0_feat)\n",
        "\n",
        "       \n",
        "       \n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\n",
        "        \n",
        "        # print(\"mu_0\", mu_0_target_class)\n",
        "        # print(\"mu_1\", mu_1_target_class)\n",
        "\n",
        "        ones = np.ones(shape = batch_size_test)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        \n",
        "     \n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'mean')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class   \n",
        "\n",
        "        sum_of_losses = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "       \n",
        "        batch_loss.append(sum_of_losses)\n",
        "        \n",
        "\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\n",
        "        # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "        \n",
        "        \n",
        "        \n",
        "        #end for\n",
        "    batch_loss  = list(batch_loss)\n",
        "    test_losses.append( sum(batch_loss) / len(batch_loss) ) \n",
        "    \n",
        "\n",
        "    \n",
        "   \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(all_losses, color='green',label='train')\n",
        "plt.title('train vs test')\n",
        "plt.xlabel('epoch_num')\n",
        "plt.ylabel('loss sum')\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(test_losses, color='blue',label='test')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".......................... epoch = 0 ..........................\n",
            "-7275.33287389949\n",
            "work with test dataset\n",
            ".......................... epoch = 1 ..........................\n",
            "-8342.911316879094\n",
            "work with test dataset\n",
            ".......................... epoch = 2 ..........................\n",
            "-611123.7049457598\n",
            "work with test dataset\n",
            ".......................... epoch = 3 ..........................\n",
            "-783300.762356434\n",
            "work with test dataset\n",
            ".......................... epoch = 4 ..........................\n",
            "-1313361.2020577732\n",
            "work with test dataset\n",
            ".......................... epoch = 5 ..........................\n",
            "-989843.8938561417\n",
            "work with test dataset\n",
            ".......................... epoch = 6 ..........................\n",
            "-1170888.0309360344\n",
            "work with test dataset\n",
            ".......................... epoch = 7 ..........................\n",
            "-740651.3018418681\n",
            "work with test dataset\n",
            ".......................... epoch = 8 ..........................\n",
            "285600.76617391594\n",
            "work with test dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMrXSfMTiVDd",
        "outputId": "1d12d762-55f8-4e34-cacd-54c44ae55b6b"
      },
      "source": [
        "X_train_1 = torch.FloatTensor(X_train_1)\n",
        "X_train_0 = torch.FloatTensor(X_train_0)\n",
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "mu_1 = model(X_train_1)\n",
        "mu_0 = model(X_train_0)\n",
        "\n",
        "pred = mu_1-mu_0\n",
        "print(qini_auc_score(y_train, pred.detach().numpy(), treatment_train))\n",
        "\n",
        "print(pred)\n",
        "print(torch.min(pred))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-163578094.97352487\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<SubBackward0>)\n",
            "tensor(-0.0015, grad_fn=<MinBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz4cLfVvZHIL"
      },
      "source": [
        "proposing network with sigmoid\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3IxOEpZZEXc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8722e341-62b5-4beb-e1ea-43014b70fb23"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 35006   # Number of samples in each batch\n",
        "epoch_num = 40   # Number of epochs to train the network\n",
        "lr = 0.0001        # Learning rate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 100)\n",
        "        self.fc3 = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        m = nn.Sigmoid()\n",
        "        return m(x)\n",
        "        \n",
        "\n",
        "model = Model()\n",
        "alpha = 0.8\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)\n",
        "# model.to(device)\n",
        "# print(model)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# X_test_1_tensor = torch.FloatTensor(X_test_1) \n",
        "# X_test_0_tensor = torch.FloatTensor(X_test_0)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# treatment_test = treatment_test.to_numpy()\n",
        "# treatment_test = torch.from_numpy(treatment_test).int()\n",
        "# treatment_test = Variable(treatment_test)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# y_test = y_test.to_numpy()\n",
        "# y_test = torch.from_numpy(y_test).float()\n",
        "# y_test  = Variable(y_test)\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# Z_trans_test = Z_trans_test.to_numpy()\n",
        "# Z_trans_test = torch.from_numpy(Z_trans_test).float()\n",
        "# Z_trans_test = Variable(Z_trans_test)\n",
        "\n",
        "\n",
        "#init loaders\n",
        "# train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
        "\n",
        "\n",
        "# calculate the number of batches per epoch\n",
        "batch_per_ep = X_train.shape[0] // batch_size\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# define lists of losses to store\n",
        "all_losses  = []\n",
        "test_losses = []\n",
        "min_losses = []\n",
        "\n",
        "\n",
        "model.train()\n",
        "# epochs loop\n",
        "for ep in range(epoch_num):  \n",
        "    print(\".......................... epoch =\",ep,\"..........................\")\n",
        "    i = 0\n",
        "    # batches loop\n",
        "    for batch_n in range(batch_per_ep):  \n",
        "        batch_loss = []\n",
        "       \n",
        "        \n",
        "        batch_1_feat = torch.FloatTensor(X_train_1[i:i+batch_size])\n",
        "        batch_0_feat = torch.FloatTensor(X_train_0[i:i+batch_size])\n",
        "        \n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        batch_Z_trans = Z_trans_train[i:i+batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass (predict)\n",
        "        mu_1_target_class = model(batch_1_feat)\n",
        "        mu_0_target_class = model(batch_0_feat)\n",
        "\n",
        "        #convert to torch structure\n",
        "        treatment_batch = treatment_train[i:i+batch_size]\n",
        "        treatment_batch = treatment_batch.to_numpy()\n",
        "        treatment_batch = torch.from_numpy(treatment_batch).int()\n",
        "        treatment_batch = Variable(treatment_batch)\n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, shape = (-1,))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, shape =(-1,) )\n",
        "        \n",
        "        # print(\"mu_0\", mu_0_target_class)\n",
        "        # print(\"mu_1\", mu_1_target_class)\n",
        "\n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        \n",
        "\n",
        "       \n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "        #convert to torch structure\n",
        "        batch_label = batch_label.to_numpy()\n",
        "        batch_label = torch.from_numpy(batch_label).float()\n",
        "        batch_label = Variable(batch_label)\n",
        "\n",
        "       \n",
        "        #convert to torch structure\n",
        "        batch_Z_trans = batch_Z_trans.to_numpy()\n",
        "        batch_Z_trans = torch.from_numpy(batch_Z_trans).float()\n",
        "        batch_Z_trans = Variable(batch_Z_trans)\n",
        "        batch_Z_trans = torch.reshape(batch_Z_trans, shape = (-1,))\n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'mean')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "        \n",
        "        \n",
        "        # print(\"uplift_pred\", uplift_pred)\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "        sum_of_losses = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "        # print(loss_contrastive)\n",
        "        batch_loss.append(sum_of_losses)\n",
        "        # print(\"train AUQC:\", qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\n",
        "        # print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "        \n",
        "        # Backward pass and updates\n",
        "        sum_of_losses.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        i += batch_size\n",
        "        #end for !!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    # plot_qini_curve(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy())\n",
        "    print(qini_auc_score(batch_label.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_batch.cpu().detach().numpy() ))\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss) ) \n",
        "\n",
        "    # #work with test dataset\n",
        "\n",
        "    # mu_1 = model(X_test_1_tensor)\n",
        "    # mu_0 = model(X_test_0_tensor)\n",
        "\n",
        "    # mu_1_target_class = mu_1\n",
        "    # mu_0_target_class = mu_0\n",
        "\n",
        "    # ones = np.ones(shape = X_test_1.shape[0])\n",
        "    # ones = torch.from_numpy(ones).float()\n",
        "\n",
        "    # #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "    # uplift_pred_Y = treatment_test * mu_1_target_class + (ones - treatment_test) * mu_0_target_class \n",
        "\n",
        "    # mu_0_target_class = torch.reshape(mu_0_target_class, (-1,))\n",
        "    # mu_1_target_class = torch.reshape(mu_1_target_class, (-1,))\n",
        "    \n",
        "\n",
        "    \n",
        "   \n",
        "    \n",
        "    # #declare losses\n",
        "    # loss_cross = nn.BCELoss(reduction = 'mean')\n",
        "    # loss_MSE = nn.MSELoss()\n",
        "\n",
        "    # #implements uplift_predicted = mu_1 - mu_0\n",
        "    # uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "\n",
        "    # sum_of_losses =torch.mean(  (1-alpha) * loss_MSE(Z_trans_test, uplift_pred) + alpha * loss_cross( uplift_pred_Y, y_test) )\n",
        "    # test_losses.append(sum_of_losses)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(all_losses, color='green')\n",
        "plt.title('sum_of_losses')\n",
        "plt.show()\n",
        "\n",
        "# plt.plot(test_losses, color='blue')\n",
        "# plt.title('sum_of_losses')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".......................... epoch = 0 ..........................\n",
            "575714.2897998542\n",
            ".......................... epoch = 1 ..........................\n",
            "687202.8238649331\n",
            ".......................... epoch = 2 ..........................\n",
            "821170.2098770794\n",
            ".......................... epoch = 3 ..........................\n",
            "-594238.355457807\n",
            ".......................... epoch = 4 ..........................\n",
            "191489.89595435932\n",
            ".......................... epoch = 5 ..........................\n",
            "1920812.4279926438\n",
            ".......................... epoch = 6 ..........................\n",
            "1839840.097914366\n",
            ".......................... epoch = 7 ..........................\n",
            "778815.5585964136\n",
            ".......................... epoch = 8 ..........................\n",
            "1455925.2160117794\n",
            ".......................... epoch = 9 ..........................\n",
            "2076258.8061467446\n",
            ".......................... epoch = 10 ..........................\n",
            "2738230.5120166615\n",
            ".......................... epoch = 11 ..........................\n",
            "1853678.505014794\n",
            ".......................... epoch = 12 ..........................\n",
            "2450358.138733534\n",
            ".......................... epoch = 13 ..........................\n",
            "2147957.121447131\n",
            ".......................... epoch = 14 ..........................\n",
            "2552635.7373040766\n",
            ".......................... epoch = 15 ..........................\n",
            "1805233.1827804726\n",
            ".......................... epoch = 16 ..........................\n",
            "1148075.4175973237\n",
            ".......................... epoch = 17 ..........................\n",
            "1170194.9811164923\n",
            ".......................... epoch = 18 ..........................\n",
            "471444.60621031\n",
            ".......................... epoch = 19 ..........................\n",
            "1346506.473734798\n",
            ".......................... epoch = 20 ..........................\n",
            "-23812.826806133613\n",
            ".......................... epoch = 21 ..........................\n",
            "759041.7131702639\n",
            ".......................... epoch = 22 ..........................\n",
            "-691033.1019856185\n",
            ".......................... epoch = 23 ..........................\n",
            "-441085.3017783463\n",
            ".......................... epoch = 24 ..........................\n",
            "-84527.02294531092\n",
            ".......................... epoch = 25 ..........................\n",
            "2313822.515541978\n",
            ".......................... epoch = 26 ..........................\n",
            "677511.6228257585\n",
            ".......................... epoch = 27 ..........................\n",
            "1645596.390698839\n",
            ".......................... epoch = 28 ..........................\n",
            "1645727.1777001042\n",
            ".......................... epoch = 29 ..........................\n",
            "1640467.224699339\n",
            ".......................... epoch = 30 ..........................\n",
            "2542919.870307885\n",
            ".......................... epoch = 31 ..........................\n",
            "-399060.48844520375\n",
            ".......................... epoch = 32 ..........................\n",
            "1999438.365632832\n",
            ".......................... epoch = 33 ..........................\n",
            "1870171.3823795225\n",
            ".......................... epoch = 34 ..........................\n",
            "-1041026.5165932886\n",
            ".......................... epoch = 35 ..........................\n",
            "-1217167.648373058\n",
            ".......................... epoch = 36 ..........................\n",
            "-1722858.4832810126\n",
            ".......................... epoch = 37 ..........................\n",
            "-641658.0062462017\n",
            ".......................... epoch = 38 ..........................\n",
            "1088606.8971623108\n",
            ".......................... epoch = 39 ..........................\n",
            "1793535.6802830212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpsL9Oq8PKVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "156244b0-819b-44ed-9d48-cc693478cfdf"
      },
      "source": [
        "X_train_1 = torch.FloatTensor(X_train_1)\n",
        "X_train_0 = torch.FloatTensor(X_train_0)\n",
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "mu_1 = model(X_train_1)\n",
        "mu_0 = model(X_train_0)\n",
        "\n",
        "pred = mu_1-mu_0\n",
        "print(qini_auc_score(y_train, pred.detach().numpy(), treatment_train))\n",
        "\n",
        "print(pred)\n",
        "print(torch.max(pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-163578094.97352487\n",
            "tensor([[1.0186e-03],\n",
            "        [6.4969e-06],\n",
            "        [4.1914e-04],\n",
            "        ...,\n",
            "        [1.0187e-03],\n",
            "        [9.6339e-04],\n",
            "        [1.5497e-06]], grad_fn=<SubBackward0>)\n",
            "tensor(0.0022, grad_fn=<MaxBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFLXT97dapoc"
      },
      "source": [
        "example of siamese network!!!!\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzEBJvdtZdi-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "fab2c1e5-f1e9-48c8-9101-9408a9c42769"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 55   # Number of samples in each batch\n",
        "epoch_num = 12      # Number of epochs to train the network\n",
        "lr = 0.001        # Learning rate\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 100)\n",
        "        self.fc3 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return torch.exp(F.log_softmax(x,dim=1))    # F.log_softmax = log( exp(x_i) / exp(x).sum() )\n",
        "        #return x\n",
        "\n",
        "\n",
        "\n",
        "model = Model()\n",
        "alpha = 0.9\n",
        "\n",
        "\n",
        "# calculate the number of batches per epoch\n",
        "batch_per_ep = X_train.shape[0] // batch_size\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# X_test_1_tensor = torch.FloatTensor(X_test_1)\n",
        "# X_test_0_tensor = torch.FloatTensor(X_test_0)\n",
        "\n",
        "# treatment_test = treatment_test.to_numpy()\n",
        "# treatment_test = torch.from_numpy(treatment_test).int()\n",
        "# treatment_test = Variable(treatment_test)\n",
        "\n",
        "# y_test = y_test.to_numpy()\n",
        "# y_test = torch.from_numpy(y_test ).float()\n",
        "# y_test  = Variable(y_test )\n",
        "\n",
        "\n",
        "# #convert to torch structure\n",
        "# Z_trans_test = Z_trans_test.to_numpy()\n",
        "# Z_trans_test = torch.from_numpy(Z_trans_test).float()\n",
        "# Z_trans_test = Variable(Z_trans_test)\n",
        "\n",
        "# Z_trans_test = torch.reshape(Z_trans_test, (X_test_1.shape[0],1))\n",
        "\n",
        "all_losses  = []\n",
        "test_losses = []\n",
        "min_losses = []\n",
        "\n",
        "for ep in range(epoch_num):  # epochs loop\n",
        "    print(\"..........................epoch =\",ep,\"..........................\")\n",
        "    i = 0\n",
        "    for batch_n in range(batch_per_ep):  # batches loop\n",
        "        batch_loss = []\n",
        "       \n",
        "        \n",
        "        batch_1_feat = torch.FloatTensor(X_train_1[i:i+batch_size])\n",
        "        batch_0_feat = torch.FloatTensor(X_train_0[i:i+batch_size])\n",
        "        \n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        batch_Z_trans = Z_trans_train[i:i+batch_size]\n",
        "\n",
        "        # Reset gradients\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        mu_1 = model(batch_1_feat)\n",
        "        mu_0 = model(batch_0_feat)\n",
        "\n",
        "        mu_1_target_class = mu_1[:,1]\n",
        "        mu_0_target_class = mu_0[:,1]\n",
        "\n",
        "        treatment_batch = treatment_train[i:i+batch_size]\n",
        "        treatment_batch = treatment_batch.to_numpy()\n",
        "        treatment_batch = torch.from_numpy(treatment_batch).int()\n",
        "        treatment_batch = Variable(treatment_batch)\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, (batch_size,1))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, (batch_size,1))\n",
        "        #convert to torch structure\n",
        "        batch_label = batch_label.to_numpy()\n",
        "        batch_label = torch.from_numpy(batch_label).float()\n",
        "        batch_label = Variable(batch_label)\n",
        "\n",
        "       \n",
        "        #convert to torch structure\n",
        "        batch_Z_trans = batch_Z_trans.to_numpy()\n",
        "        batch_Z_trans = torch.from_numpy(batch_Z_trans).float()\n",
        "        batch_Z_trans = Variable(batch_Z_trans)\n",
        "\n",
        "        batch_Z_trans = torch.reshape(batch_Z_trans, (batch_size,1))\n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "        \n",
        "\n",
        "        \n",
        "        loss_contrastive = torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "        \n",
        "        batch_loss.append(loss_contrastive)\n",
        "        \n",
        "\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Backward pass and updates\n",
        "        loss_contrastive.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        i += batch_size\n",
        "        #end for!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss)) \n",
        "    #work with test dataset\n",
        "\n",
        "    # mu_1 = model(X_test_1_tensor)\n",
        "    # mu_0 = model(X_test_0_tensor)\n",
        "\n",
        "    # mu_1_target_class = mu_1[:,1]\n",
        "    # mu_0_target_class = mu_0[:,1]\n",
        "\n",
        "    # ones = np.ones(shape = X_test_1.shape[0])\n",
        "    # ones = torch.from_numpy(ones).float()\n",
        "\n",
        "    # #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "    # uplift_pred_Y = treatment_test * mu_1_target_class + (ones - treatment_test) * mu_0_target_class \n",
        "\n",
        "    # mu_0_target_class = torch.reshape(mu_0_target_class, (X_test_1.shape[0],1))\n",
        "    # mu_1_target_class = torch.reshape(mu_1_target_class, (X_test_1.shape[0],1))\n",
        "    \n",
        "\n",
        "    \n",
        "   \n",
        "    \n",
        "    # #declare losses\n",
        "    # loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "    # loss_MSE = nn.MSELoss()\n",
        "\n",
        "    # #implements uplift_predicted = mu_1 - mu_0\n",
        "    # uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "\n",
        "    # loss_contrastive =torch.mean(  (1-alpha) * loss_MSE(Z_trans_test, uplift_pred) + alpha * loss_cross( uplift_pred_Y, y_test))\n",
        "    # test_losses.append(loss_contrastive)\n",
        "    \n",
        "    # print(qini_auc_score(y_test.cpu().detach().numpy(), uplift_pred.cpu().detach().numpy(), treatment_test.cpu().detach().numpy() ))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_losses,color='blue')\n",
        "# plt.plot(test_losses, color='green')\n",
        "plt.title('Contrastive Loss')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(all_losses,color='blue')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..........................epoch = 0 ..........................\n",
            "..........................epoch = 1 ..........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-bc67e3ad9877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mloss_contrastive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_MSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_Z_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muplift_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_cross\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0muplift_pred_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_contrastive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2526\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOQ_S5FGayLT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "\n",
        "batch_size = 55   # Number of samples in each batch\n",
        "epoch_num = 20      # Number of epochs to train the network\n",
        "lr = 0.001        # Learning rate\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(334, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3 = nn.Linear(200, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return torch.exp(F.log_softmax(x,dim=1))\n",
        "        #return x\n",
        "\n",
        "\n",
        "\n",
        "model = Model()\n",
        "alpha = 0.8\n",
        "\n",
        "\n",
        "# calculate the number of batches per epoch\n",
        "batch_per_ep = X_train.shape[0] // batch_size\n",
        "\n",
        "# define the loss (criterion) and create an optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Z_trans_test = torch.reshape(Z_trans_test, (X_test_1.shape[0],1))\n",
        "all_losses  = []\n",
        "min_losses =[]\n",
        "for ep in range(epoch_num):  # epochs loop\n",
        "    print(\"..........................epoch =\",ep,\"..........................\")\n",
        "    i = 0\n",
        "    for batch_n in range(batch_per_ep):  # batches loop\n",
        "        batch_loss = []\n",
        "       \n",
        "        \n",
        "        batch_1_feat = torch.FloatTensor(X_train_1[i:i+batch_size])\n",
        "        batch_0_feat = torch.FloatTensor(X_train_0[i:i+batch_size])\n",
        "        \n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        batch_Z_trans = Z_trans[i:i+batch_size]\n",
        "\n",
        "        # Reset gradients\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        mu_1 = model(batch_1_feat)\n",
        "        mu_0 = model(batch_0_feat)\n",
        "\n",
        "        mu_1_target_class = mu_1[:,1]\n",
        "        mu_0_target_class = mu_0[:,1]\n",
        "\n",
        "        treatment_batch = treatment_train[i:i+batch_size]\n",
        "        treatment_batch = torch.from_numpy(treatment_batch).int()\n",
        "        treatment_batch = Variable(treatment_batch)\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        ones = np.ones(shape = batch_size)\n",
        "        ones = torch.from_numpy(ones).float()\n",
        "        #implements mu = T * mu_1 + (1-T) * mu_0\n",
        "        uplift_pred_Y = treatment_batch * mu_1_target_class + (ones - treatment_batch) * mu_0_target_class \n",
        "\n",
        "\n",
        "        mu_0_target_class = torch.reshape(mu_0_target_class, (batch_size,1))\n",
        "        mu_1_target_class = torch.reshape(mu_1_target_class, (batch_size,1))\n",
        "        #convert to torch structure\n",
        "        batch_label = torch.from_numpy(batch_label).float()\n",
        "        batch_label = Variable(batch_label)\n",
        "\n",
        "       \n",
        "        #convert to torch structure\n",
        "        batch_Z_trans = batch_Z_trans.to_numpy()\n",
        "        batch_Z_trans = torch.from_numpy(batch_Z_trans).float()\n",
        "        batch_Z_trans = Variable(batch_Z_trans)\n",
        "\n",
        "        batch_Z_trans = torch.reshape(batch_Z_trans, (batch_size,1))\n",
        "        \n",
        "        #declare losses\n",
        "        loss_cross = nn.BCELoss(reduction = 'sum')\n",
        "        loss_MSE = nn.MSELoss()\n",
        "\n",
        "        #implements uplift_predicted = mu_1 - mu_0\n",
        "        uplift_pred = mu_1_target_class - mu_0_target_class \n",
        "\n",
        "        loss_contrastive =torch.mean(  (1-alpha) * loss_MSE(batch_Z_trans, uplift_pred) + alpha * loss_cross( uplift_pred_Y, batch_label))\n",
        "\n",
        "        batch_loss.append(loss_contrastive)\n",
        "        \n",
        "        # print(batch_n, loss_contrastive)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Backward pass and updates\n",
        "        loss_contrastive.backward()                     # calculate the gradients\n",
        "        optimizer.step()                    # update the weights\n",
        "        i += batch_size\n",
        "    batch_loss  = list(batch_loss)\n",
        "    all_losses.append( sum(batch_loss) / len(batch_loss)) \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_losses)\n",
        "plt.title('Contrastive Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCOiW7WcMNUc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(all_losses[:210000])\n",
        "plt.title('Contrastive Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}